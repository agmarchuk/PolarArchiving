
# Система создания, поддержания, редактирования и публикации электронных архивов документов

Техническое название системы: Тургунда. Система может быть использована для формирования конкретных электронных архивов, репозиториев документов и электронных музеев. Система построена на фактографическом подходе, когда излагаются факты (документы, данные) в некоторой системе классов сущностей и отношений. Например, в архив помещается письмо как документ. Это означает, что вносится отсканированная электронная копия документа, заполняются поля о дате написания, авторе, получателе, возможно добавляются в базу данных упомянутые в письме персонажи, события, делается географическая привязка и т.д. Таким образом, пользователь электронного архива может не только посмотреть скан письма, но и получить довольно широкий спектр дополнительной информации и, пойдя по ссылкам, может узнать какие документы еще связаны с данным автором/получателем/персонажем, какая другая информация имеется про упомянутые организации, географические объекты.

Система поддерживает определенный набор мультимедиа документов, также допускает сохранение произвольных файлов и файловых сборок. Интерфейс Тургунды позволяет визуализировать и озвучивать основные форматы документов, а "портретное" изображение документов и сущностей, позволяет удобно представлять данные о них и об их связях с другими сущностями. 

Система предназначена для индивидуального и коллективного использования. Например, у вас есть множество документов (фотографии, видео, бумажные документы), которое хочется сохранить (навечно!). И вы помните или можете узнать кто, что, когда и почему отражены в документах. Вы вносите документы в архив и описываетет каждый из них. Хотя бы по-минимуму. Структуру документов можно сформировать ту, которая адекватна или близка их сути. Например, можно группировать документы по активностям, этапам жизни и творчества, по географии и т.д. Описание документов, свзяывание документов с персонами, огранизационными системами, географическая привязка дадут дополнительную струкутризацию документов и данных, внесенных в архив.

В случае коллективной и профессиональной работы по формированию архива, система позволяет выделять пользователей с разными ролями в отношении внесения и редактирования информации и управления коллективной работой.

## Hello World! Пример работы с системой
Для некоторого первичного знакомства с системой, можно поработать с тестовой системой. В ней есть некоторая случайно собранная информация и документы. Не бойтесь, вы ничего не испортите. Итак запускаем ресурс http://gea.iis.nsk.su/OATest

Данный ресурс чисто демонстрационный и  учебный. Для начала можно поискать что-нибудь. Поиск ведется по имени (Фамилия Имя Отчество для людей) или по его начальной части.  

## Разворачивание приложения Turgunda7 на сервере
Необходимо иметь дистрибутив (директория с файлами и поддиректориями), соответстующий платформе сервера. Напр. дистрибутив для Windows. Это делается через администартивную систему для IIS - Диспетчер служб для IIS. Необходимо под пулом приложений, относящихся к .NET Core, создать приложение, определив имя приложения (как вам нужно) и виртуальную папку (где дистрибутив). Обычно также надо определить настройти безопасности для рабочей подпапки wwwroot - нужно добавить группу пользователей IIS_IUSR и позволить чтения и записи.

При запуске этого приложения через Web, напр. http://localhost/имя_приложения
появится начальная страница, на ней может быть что-то неписано типа "Открытый архив СО РАН (редактирующее приложение)". Могут появиться и ошибки, тогда надо что-то исправлять. В случае корректного запуска, у вас появится приложение с пустой базой данных, с пустой базой документов, с отсутствующим списком редакторов и администраторов. 

Поскольку предполагается, что приложение устанавливает и первый раз запускает администратор системы, или лицо, выполняющее эту роль, надо провести еще некоторые мероприятия. Надо нажать на гиперссылку "ред" и потом нажать на "Регистрация пользователя", где зарегистрироваться под каким-то именем, указав пароль. Важно знать, что первый, кто зарегистрировался, автоматически становится администратором. Дальнейшие регистрации других пользователей будут присваивать им роль пользователя. Роль администратора может быть добавлена пользователю только администратором через специальные действия (см. далее).

Теперь можно потренироваться в работе с системой. В сущности, система представляет собой специальную базу данных. Можно создавать запись о сущности, можно редактировать запись о сущности, можно уничтожать запись. Список классов сущностей можно посмотреть в выпадающем меню (combobox) второго поля ввода. Если поставить серектор на пробел, то это "все". Для начала, полезно проверить что имеется в базе данных. Надо в режиме "все", просто нажать на кнопку "искать". Скорее всего, список объектов базы данных будет пустым. Попытки добавить объекты, скорее всего будут безуспешными. Дело в том, что распределенная база данных системы, размещается в так называемых кассетах. Кассеты - это специфические объекты, предназначенные для хранения документов и баз данных. Нет кассет, нет документов и данных. 

Администратору позволено создавать новые кассеты. Делается это по схеме: в поисковом интерфейсе задается имя новой кассеты, задается тип "Кассета", нажимается кнопка "искать". Если кассета с таким именем будет найдена, не стоит создавать новую с этим же, если не будет найдена, нужно нажать на команду [нов.]. Кассета будет создана и появится интерфейс редактироваия записи кассеты. Можно не торопиться использовать этот интерфейс и снова вернуться к кнопке "искать". Теперь ее нажатие уже выдает один элемент, это собственно кассету, которую мы создали, нажатие на эту ссылку выведет нас на редактирование записи о сущности, в данном случае, на редактирование записи о кассете. Не торопитесь редактировать кассету, давайте сначала освоим просто редактирование любой сущности. Что это значит? Еще раз посмотрите набор классов сущностей. Это персоны, организации (организационные системы), фото, видео, аудио и просто документы, коллекции, географичесие понятия и некторые другие. 

###TODO: я убрал в ApplicationProfile0.xml неправильную сущность collection-member, добавленную Алексеем. Надо проверить правильность и распространить изменение на места использования.

Поучимся. Введем новую сущность, напр. персону. Для этого, через выпадающее меню определим класс сущности "Персона" и зададим желаемой имя или его начальную часть. Например, поищем персону "Пупкин". Наберем без кавычек имя и нажмем "искать". Естественно, такой сущности пока нет, что и будет неявно сказано, но появится команда [нов.], нажмем ее, сущность (персона) будет заведена и мы перейдем в интерфейс просмотра/редактирования записи. Если повнимательнее посмотреть на информацию, то легко обнаружить, что она состоит из класса сущностей (Персона), некоторых заголовков курсивом, строчки с именем персоны и далее идет разделы, о которых можно будет узнать далее. Собственно запись - одна строчка, которая пока содержить только имя. Нажмем команду ред (редактировать) в этой строчке. Одна строчка преобразуется в вертикально расположенную таблицу поле-значение. Поле имя уже заполнено, остальные - нет. В данной системе не обязательно заполнять все поля, жалетельно заполнить те, информация о которых у вас имеется. Например, отредактируем первое поле до канонического ФИО, я набрал Пупкин Василий Васильевич, дату "рождения" 1983-04-01 и поле описания типа "Персонаж анекдотов эпохи застоя". При нажатии "записать!", информация будет записана в базу данных и отобразится в интерфейсе в одну строчку. Причем сверху расположены имена полей, а в основной строчке значения этих полей. 

В некоторых редакторах фиксация результатов редактирования не происходит, напр. в Internet Explorer, рекомендуем использовать Google Chrome. 

Двинемся дальше. Как всегда, можно посмотреть список имеющихся в базе данных сущностей, теперь их уже две. И видно, что каждая отмечается своим классом и именем, оформленным как гиперссылка. Аналогично вводятся и редактируются и другие сущности. Теперь важно освоить связи между сущностями и их редактирование. Напр. между персоной Пупкин и организацией "Смешная организация" мы бы хотели установить связь. Для этого, перейдем, напр. через поиск, на запись Пупкина и обратитм внимание на пока не заполненный раздел "участник в орг.". Нам нужен новый участник, нажимаем [нов] этого раздела. Появляется форма редактирования участия. В ней - пока не заполненное поле "в орг. сист.", роль и др. Наберем название желаемой организационной системы "Смешная организация" и (внимание!), нажмем кнопку "пров" - проверить. Это нужно для проверки имеется ли такая организация в базе данных или еще нет. Мы получим пустой список, как всегда, нажмем [нов]. А затем уже нажмем "записать!". Организация будет создана и связь между Пупкиным и организацией также будет установлена. Теперь можно нажать на гиперссылку организации и переместиться в ее запись.  

На самом деле, выходя на ту или иную сущность, мы видим не только ее запись, но и связи этой сущности с другими. Нажав на гиперссылку, мы удидим и запись организации и то, что там есть работник/участник Пупкин. Такой вид представления информации мы называем информационным портретом сущности. В зависимости от класса сущности, информационный портрет выглядит по-разному. Изменяются поля записи для разных классов сущностей, изменяется набор и смысл отношений. Кроме бинарных отношений сущность-сущности, есть и унарные "отношения", устанавливаемые для сущности. Вернемся к портрету Пупкина. Раздел "именуется" как раз представляет альтернативное имя персоны. Создадим новое отношение, нажав (как всегда [нов]), введем другое имя напр. Вася. Как ни странно, люди меняют свои имена, фамилии (особенно женщины), отчества, могут быть варианты имен на других языках и т.д. Как и других отношений, дополнительных имен может быть несколько. Другой вариант унарного отношения: степень/титул. Имеется ввиду научные и др. степени, напр. доктор биологических наук, звания - профессор, заслуженный деятель науки, академик и титул - князь, граф, барон, сэр, пэр и др.

Теперь вы уже без труда справитесь с установлением отношения типа "проживание" Пупкина с каким-то географическим объектом. В результате Выших усилий довольно быстро может начать появляться база данных, отражающая какие-то знания о реальности или придуманности. 

Теперь перейдем к документам. Документы являются тем, что предлагаемая система архивирует и являются основой фактографического подхода. Документ - это целостная информация, зафиксированная на каком-то носителе. Мы работаем в основном с цифровыми документами или с цифровыми копиями документов. В узком смысле, цифровой архив - склад таких документов. Это могут быть фотографии, сканы документов, видео, аудио, документы в специальных форматах doc, pdf, rtf, html и др. У документов - два "лица". С одной стороны, это цифровой контент, в конечном итоге, набор байтов и способ интерпретации этих байтов. С другой строны, это запись в базе данных, это сущность. У документа может быть имя, дата создания, автор или авторы, получатель. Документ отражает какие-то сущности реального мира - людей, организационные системы, географические системы и даже другие документы. 

Попробуем сформировать документ. Рекомендуемый нашими информационными специалистами способ - берем "страницы книжки", формируем из них "книжку" и описываем ее. Проще всего, мыслить сканами страниц книжки. Представим, что у нас есть набор сосканированных страниц какого-то документа ("книжки"). Начнем с того, чтобы ввести в архив сканы страниц. Для пробы - это могут быть любые картинки (имиджи), имеющиеся на вышем компьютере. Ввод картинок в архивную систему осуществляется как загрузка (upload) в конкретную кассету перечисленных пользователем файлов. Мы пока завели одну кассету, в нее и будем загружать. Это делается через страницу кассеты. Задаем в поисковом интерфейсе класс "Кассета", нажимаем на поиск, находим кассету переходим на ее портрет. Теперь внимательно посмотрим на формы, находящиеся перед портретом. Это только для кассет. Первая однострочная форма - загрузка файлов в данную кассету. Нажмем на "Выбрать файлы", найдем на компьютере условные сканы, напр. любые картинки в разделе "Изображения", отметим их и нажмем "Открыть", а потом кнопку Upload. Картинки попадут в коллекцию под названием upload. Если имена файлов были правильно отсортированы, напр. лексически увеличивалися с ростом номера скана, то и в коллекции они будут располагаться в нужном порядке, если нет, то придется искать следующую сраничку для обработки. Выберем первую страницу, перейдем на нее. В ее информационном портрете есть имя файла, используемое в качестве имени страницы и есть отношение принадлежности страницы папке "upload". 

Рекомендуемая методика дальнейших действий заключается в заполнении отношения "содержится в", нажмем на [нов]. 

Заведем новый объект класса "документ", пусть это будет как-бы книжка. Как всегда, заведение сущности делается через поисковый интерфейс, указав класс сущности и имя сущности. Классом у нас будет "Документ", имя, напр. "Книжка в картинках".  

## Документация по работе с системой Тургунда (Turgunda7)

Исходный вариант (текст) системы находится в репозитории https://github.com/agmarchuk/PolarArchiving в виде решениия (Solution) для VisualStudio или .NET Core. Для его применения сначала надо "изготовить" бинарный дистрибутив для конкретной платформы. В данном случае, предполагается платформа Windows-7/10 с 64-разрядной архитектурой. Изготовление дистрибутива будем выполнять в .NET Core, для этогоо удобно использовать Visual Studio Code https://code.visualstudio.com/?wt.mc_id=DX_841432. Естественно, также надо иметь установленным пакет .NET Core https://docs.microsoft.com/ru-ru/dotnet/core/ версии  2.1 или выше.

В решении PolarArchiving находим проект src\Turgunda7. В решении также  должны присутствовать проекты CassetteCore и TurgundaCommon. Также используются через Nuget компоненты PolarDB. Все указанное должно подключиться автоматически (PolarDB - при наличии фукционирующего Интернета).

Параметры изготавливаемого дистрибутива задаются в конфигураторе, в частности, в разделе
```
  <PropertyGroup>
    <TargetFramework>netcoreapp2.0</TargetFramework>
    <OutputType>Exe</OutputType>
    <RuntimeIdentifier>win10-x64</RuntimeIdentifier>
  </PropertyGroup>
  ```
См. документацию .NET Core по установке и публикации. 

В директории src\Turgunda7 запускаем 
```
dotnet publish -c Release
```
Если все правильно, то "где-то в глубине", скорее всего в директории bin\Release\netcoreapp2.0\win10-x64\publish, буде создан образ, которы можно перемещать и запускать. "Заберем" эту директорию переместив куда-нибудь или, для начала, будем работать с ней в указанном месте. Для информации: там загрузилось много модулей кода, создано приложение Turgunda7.exe, есть web.config (это все же  web-приложение!), есть директория Views с "остатками" вида страниц, есть папка wwwroot -  рабочая область приложения, там есть важные для приложения файлы и там будут создаваться файлы и директории. В принципе, все это знать необязательно, важно уметь запускать приложение - тот самый исполняемый файл Turgunda7.exe. Можно сразу его запустить. 

Брандмауэр может "ругнуться", но если вы хотите поработать с системой, то разрешите запуск этого приложения, в дальнейшем, брандмауэр учтет ваш выбор и ругаться не будет. В окне запуска приложение, которое останется на экране можно прочитать, что приложение запущено, и ждет клиента на данной машине по но меру порта 52018. Наберите http://localhost:52018, появитсяя интерфейс приложения. 

Обязательно надо зарегистрироваться и войти через вход ред (редактировать) - первый зарегистрировавшийся автоматически становится администратором данного экземпляра системы и данной базы данных. Пока база данныых - пустая. Следующее обязательное действие - создание кассеты в базе данных. 

### 20181219 14:52
В прошлый раз я застрял на некоторых непродуманных обстоятельствах.

Первое. Дистрибутив Тургунды переносится только без локально созданных кассет. Здесь теоретически можно было бы начать внедрять относительные имена файлов, но что-то есть сомнения. Путь будет так. А дистрибутив надо делать или без директории для кассет или без кассет. 

Второе. С универсальной последовательностиью надо что-то делать. Одно из действий - сканирование элементов. Если есть только признаки isnull и mT, эффекттивное сканирование организовать трудно. Можно по индексу ключа пробежаться, то это будет "дергатня". Можно добавить еще однин признак unused, истинность которого значить неиспользование данной записи. Но нужен ли тогда отдельный признак isnull? Если все элементы заданного ключа помечены unused, в результате элемент по ключу будет ненайден. Однако, рано "хоронить" isnull. Он необходим в распределенной системе - "занулили" в одной секции, получили результат везде, а не только в этой секции. Итак, три признака - один длинное целое и два булевских. Можно как-то побитно разметить отдельный байт. Теперь сканировать понятно как. 

Третье. Оказалось, что пока реализации такого подхода нет. Совсем нет. Есть какие-то заготовки в пространстве имен Polar.DB, но целостного решения, тем более - библиотечного решения пока нет. Посмотрю как я использовал эти заготовки в Polar.Datanode. Попробую написать программу. Расширю GetStarted на новый эксперимент Program12.

Что-то написал. Последовательность записей, состоящей из целого ключа, строкового имени и вещественного возраста, создается в количестве 100 млн. записей. Создается индекс, состоящий из массива ключей и массива офсетов. В тесте - это несколько больше, чем 3 Гб. Выборка по случайному ключу: 80 мс. / 10 тыс. Вполне прилично. Но индекс пока разворачивается в массивах.  

### 20181220 07:53
Вчера поработал над универсальной последовательностью. Пока провел эксперимент, когда завел последовательность и индекс к последовательности и тестирую ввод и скорость выборки по ключу. Получается неплохо.   

Ввод и построение индекса для 10 млн. элементов выполняется за 10.8 сек. (домашний компьютер), 10 тыс выборок - за 64 мс. Можно несколько ускорить ввод, для этого не нужно перекидывать индекс туда-сюда. В принципе, политика использования оперативной памяти должна определяться динамически исходя из размеров задачи и выделенных ресурсов. Буду считать, что задача среднего размера (до 100 млн. элементов) и ресурсов достаточно для сортировки в ОЗУ. 

Теперь, индекс сначала накапливается в массивах, потом сортируется, потом записывается в потоки. Получилось: загрузка 7 сек., выборка 10 тыс. 65 мс. Следующий шаг определить существенно ли влияет бинарный поиск ключа на скорость.  

Влияет, но не сильно. На 10 млн. элементов получилось 56-57 мс. / 10 тыс. выборок
100 млн. как-то опять не получилось. Загрузка выполнилась довольно быстро за 82 сек., но потом программа видимо замедлилась и скорость выборки даже неприлично воспроизводить. А на 50 млн. элементов - все в порядке. Загрузка 36 сек., выборка 72 мс. и 60 мс. для полного и тестового (только чтение из последовательности) вариантов. В режиме toload=false получилось: 74 и 59.

Теперь попробую отказаться от повторного использования массива офсетов. Время ровно удвоилось, что логично... Теперь надо посмотреть сработает ли на 100 млн. 
```
10 млн.
7 сек., 121 мс., без загрузки 120-122
50 млн.
25 сек., 126 мс., без загрузки 126-128
100 млн. 
46 сек., 71 сек., без загрузки 56 сек... 
50 млн.
21 сек., 159 мс., без загрузки 127-129
100 млн. 
49 сек., 59 сек., без загрузки 39 сек... 

На рабочем (16 Гб ОЗУ)
100 млн. 
49 сек., 150 мс., без загрузки 142 мс. 
200 млн. 
99 сек., 157 мс.
400 млн.
350 сек., 222 сек. увы... 
```

### 20181221 02:00
Что-то не спится. Наверное потому, что рынок "валится", а я не знаю что делать... Решил поработать.

Что я сделал и чего не сделал? Во-первых - концепция. Есть некоторые нюансы, а так вроде уже что-то получается. Есть некоторая выделенность ключа, но в этом есть смысл. Смысл заключается в наборе редактирующих действий. Действительно, нужна полнота операций редактирования. То есть такие средства, чтобы можно было бы через элементарные действия перевести любой корректный набор элементов в любой другой. Очевидно, что эти действия - добавление и уничтожение. Но если добавление делается совсем просто, то для уничтожения надо иметь указатель того, что уничтожается. Пусть это будет ключем. Не столь очевидным является предположение о том, что ключ позволяет выстраивать индекс. Вроде "да", потому что и добавление и уничтожение должны делаться быстро. Но может и "нет", поскольку указатель на элемент может нарушать логику набора элементов (множества), напр. может быть каким-то офсетом. Тогда должны присутствовать операции выделения, когда по какому-то индексному построению запрос на выделение дает набор координат (офсетов). В общем, лучше в эти "дебри" не уходить, а остаться в рамках простых рассуждений. 

Итак, элементами концепции являются: 
1) множество или набор элементов;
2) ключевое значение у элемента;
3) временная отметка;
4) признак isnull;
5) признак unused.

Комментарии. По первому пункту, элементы - из множества возможных элементов. Часто - типизированные. У набора отсутствует определенный порядок и они могут быть произвольно переставлены. Все элементы попарно различные, это положение можно нарушить, но так проще. Среди элементов набора могут быть используемые и неиспользуемые. В результате воздействия на набор, некоторые используемые элементы могут превратиться в неиспользуемые. Но не наоборот. У набора есть "грязный" перечислитель элементов - это некоторый способ "выдачи" значений элементов в виде потока, причем выдаются все элементы и каждый - один раз. Можно предположить существование функции unused(element) определяющей используется элемент или нет. В принципе, такай функция кажется необязательной, но вроде с ней проще. Например, уже на этой стадии абстракции, можно отфильтровать из "грязного" потока неиспользуемые элементы и получить поток всех используемых. 

На элементах есть однозначая функция ключа, переводящая элемент в значение специального вида или типа. Этот вид или тип должен быть сравнимым на равенство и, в сложных случаях желательно, чтобы у него была хеш-функция, помогающая вычислять равенство элементов. Примером сложного случая может быть набор триплетов. В базовой семантике RDF триплеты совпадают если совпадают его части (субъект, предикат, объект). 

Я вот подумал, что признак unused не очень удобен. Действительно, мы добавляем элемент в набор и обязаны не только проверить набор на наличие старых элементов, но найти и отметить последний. Надо будет подумать по этому поводу. 

Кроме функции ключа, нужно ввести еще отметку времени. Отметак времени mT "вставляется" в элемент и служит для определения оригинала среди элементов. Все элементы с одинаковым ключем считаются разными "версиями" одного элемента и в выходном потоке или по действию get(key) выделяется тот из них, который имеет большую отметку по времени. При одинаковой отметке, берется произвольный. Почему так, а не как-то иначе? Одно из возможных объяснений заключается в том, что элемент можно быстро "положить" в (распределенный) набор, а потом уже разбираться в том, какой из элементов является оригиналом. При этом, допустимо использовать какую-то из предыдущих версий. "Уничтоженный" элемент в этой модели - не исключение. Семантика уничтожения определяется том, что можно сгенерировать элемент с заданным ключем, но дающий true на функции isnull(element).  

Уже укажывалась проблема, связанная с (только) временной отметкой. Это трудности организации сканирования элементов последовательности. Можно сканирование делать через индекс по ключу, если он позволяет, но это будет так медленно... Есть еще подход к сканированию. Можно выделить все неопределенные элементы в один набор. Как-бы изъять оттуда, где они были. Хотя физически изымать не обязательно. Этот набор сделать в виде однозначной таблицы. И тогда сканирование будет заключается в "грязном" сканировании, но все элементы проверяются на наличие в этом специальном наборе.

### 20181222 09:47
Что-то я застрял на концепции и отметках. Я вот что подумал: много зависит от парадигмы. Если считать, что новый айтем может быть помещен в любой набор - это одно, если набор предопределен - это другое. А еще я подумал о том, что временная отметка лучше соответствует семантике состояний. Я имею ввиду то, что мы можем говорить об изменении состояния базы данных. Изменение локального набора с указанием временной отметки - действие "мгновенное". Изменяется состояние только одного айтема. Если его рассматривать распределенно, то все значения айтема корректны в пределах какого-то процесса. Если это учитывать в программе, это может быть ключом к корректному решению разных задач. 

Я решил, что для прогресса в модели, нужно рассмотреть интеграцию отдельных моделей в общую. Например, есть множество отделльных и распределенных наборов, а требуется сделать корректно работающую общую базу данных. Исходный посыл уже фигурировал ранее. "Сливаются" айтемы, имеющие один ключ. По смыслу, "сливаются" они не полностью, а все становятся "одинаковыми". То есть, использование любого считается корректным. Это, конечно, УЖАСНОЕ предположение, но что поделаешь... Для компенсации предположения, можно постулировать, что некоторый синхронизационный процесс "нормализует" базу данных таким образом, что постепенно, возможно в течение определенного времени, при отсутствии новых записей, выбираемые из любой точки данные станут последними записанными. Как-то так...

Предположим, что все наборы обладают необходимыми качествами. Точнее не только сами наборы, но и локальные базы данных, построенные на их основе. Нужен какой-то новый термин для локальной базы данных. Какие качества мы имеем ввиду? Вот те самые. Все элементы доступны и запрос элемента по ключу дает последнюю его модификацию. Последнюю в локальном смысле. Идея процесса установления также неоднократно обсуждалась. Мы посылаем запрос get() всем. Кто-то на него отвечает. По предыдущим рассуждениям, этот ответ рассматриватеся как корректный. Дальше организуется "волна" по доставке оригинала айтема туда, где эхтот айтем  также присутствует. Другой вариант: волна "смывает" варианты айтемов, которые перестают быть актуальными. 

Такое устройство локального хранилища и их интеграции, в нашем "кассетном" варианте выглядит следующим образом. Есть ряд фог-хранилищ, у каждого свой владелец или это отдельное "ведро". А есть еще кеш общих данных. Вот это последнее выглядит сомнительно. Кеш - это значит можно уничтожеть. Но тогда семантика "согласованность в конце концов" потрадает. И даже если не кеш, то мы меняем конфигурацию и снова получаем несогласованность. Надо возвращаться к модели. 

### 20181224 16:31
Возвращаюсь к модели. Когда одно локальное хранилище - более или менее все понятно. А вот если есть много, хотя бы 2. Тогда для получения записи, придется опрашивать все хранилища или хотя бы избранные. Вот здесь - самое критическое место. Опрашивать все "дальние" хранилища по каждому запросу - не эффективно. Можно поступить следующим образом: опрашивать "ближнее", если там есть - выдавать. Если нет - искать дальше. Но и выдав значение, не нужно "успокаиваться", надо волну запросов продложнить в попытке найти более "свежее" значение. Даже не знаю что сказать по этому поводу. Мне кажется, раньше была конструкция эффективнее. Эта конструкция базировалась на распределенном реплицировании. В этом случае, "волна" запросов порождается не при чтении записи, а при записи. Запись (записей!) производится как правило реже чтения. На этом можно сэкономить. 

Еще можно было бы "поколдовать" с разделами. Если хранилищу приписать набор признаков, то возможны варианты. Самым простым вариантом является однозначное направление оператора чтения/записи соответствующему разделу. Но так мы лишаемся преимуществ кассетной организации и внешнего редактирования элементов. А какие могут быть варианты?

Сейчас в кассету погружаются файлы локальных определений - фог-файлы. У каждого фога есть своя префиксная составляющая. Пользователь пишет в "свой" фог-файл. Соответственно запрос по ключу может быть локализован конкретным фогом. Теоретически, можно обеспечить свойство такое, что абонент пишет только с одной группой идентификаторов. Например, можно использовать именование, датирования и reification. Может быть... Но и не обязательно.

### 20181225 12:00
Я серьезно застрял на модели. В принципе, сосредоточенная модель key-value базы данных мне понятна. И даже с элементом пользовательских секций (разделов). Не удалось развить эту модель до распределенного варианта. А так было привлекательно: есть кассета, есть ее локальная база данных, которая легко интегрируется с другими кассетами и их базами данных. Думаю, что еще можно будет подумать в этом направлении... Но вернемся на землю. Что нам нужно? Работающая база данных для Тургунды. И пока сосредоточенная на едином сервере, на котором создается сервис информационной базы. В информационную базу входят собственно файлы контента (документы и др.) и база данных. В дальнейшем, можно будет "загнать" всю информационную базу в один файл (легко!..).

Итак, что такое "стандартная" модель последовательности? 
1) Это набор элементов определенного типа. Ее можно обнулять, можно пополнять, ее можно сканировать. Состояние последовательности включает в себя число элементов, которое нужно синхронизировать Flush(), сами элементы, указатель позиции чтения/записи offset. Если указатель стоит на элементе, можно читать элемент, в некоторых случаях, писать элемент. Если указатель стоит за последним элементом, то можно писать элемент.  
2) В некоторых случаях (если элементы фиксированного размера), можно делать выборку или запись по индексу. К key-value это не имеет прямого отношения, но все же можно отметить эти свойства. 

Следующий уровень абстракции - упорядоченность элементов. Упорядоченность достигается тем, что между элементами задается отношение CompareTo(). Соответственно, отношение удовлетворяет некоторым аксиомам метрики. Можно отсортировать поледовательность по этому отношению, т.е. построить новую последовательность, в которой элементы с меньшим номером, "меньше" по заданному отношению. В принципе, процедура может быть не слишком дешевой, поскольку в общем случае требует lg(N) сканирований. Но в некоторых случаях, такая процедура нужна. 

Другой способ реализации упорядоченности заключается в построении набора офсетов такого, что Element(off1).CompareTo(Element(off2)) <= 0 если off1 < off2.   
 
Пусть в последовательности появляется ключ. Ключ - типизованное значение, вычисляемое на элементах последовательности через ключевую функцию.  

### 20181227 07:57
Я все "подкрадываюсь" и "подкрадываюсь" к модели и спецификации. Думаю, что итог будет довольно сильно походить на универсальный индекс в разделе Polar.CellIndexes. Только не будет "стандартных" ячеек, будет изменена конструкция айтема (не будет "конверта" с признаком уничтожения) и, видимо, будет явно прописана отметка времени. Кроме того, надо будет сделать "большую сортировку" и "большое упорядочивание". Как-то так...

Итак, есть простая модель последовательности типизованных элементов. Можно добавлять, можно сканировать. Если фиксированный размер элемента, то можно читать или записывать по произвольному индексу. Можно получать офсеты, можно читать по офсету, можно писать по офсету, если это последний (начало свободного пространства). Где-то я это писал. Важно, что это всего лишь полуфабрикат. А может и нет? Вроде есть две "полуфабрикатные" позиции: текущий указатель Position и количество элементов в последовательности, которое фиксируется.

Сейчас посмотрел код класса UniversalSequenceBase. Вроде все правильно. Есть сомнения в реализации AppendElement(object v) - не очевидна диагностика ошибок в использовании (!). 

Следующий уровень модели: класс UniversalSequence<T> where T: IComparable;
Где T - тип значения ключа, соответственно, вводится функция ключа.
Реализация на первый взгляд непонятна. Вроде класс определен для уже подготовленных последовательностей ( // Предполагается, что есть некоторый ключ и последовательность отсортирована по этому ключу). И там есть варианты бинарного поиска. Введена функция 
```
public Func<T, Diapason> getDia = null; // Задать можно снаружи (???)
```
но она не используется... 

Еще есть сомнение в том, что сразу надо "резко" вводить ключ. Мы пропустили этап с функцией сравнения. Кажется, надо вернуться к разбивке типа той, что есть в CellIndexes. Посмотрю код. Посмотрел, как-то не слишком прозрачно... 

Последовательность модельных расширений следующая:
а) база универсальной последовательности
б) Основные виды индексов
в) key-value последовательность

А формировать решения можно попробовать на экспериментах. Воспользуемся фототекой. По крайней мере, первой таблицей. Вернулся к уже реализованному тесту Program12. Создаю последовательность в 4 млн. записей. Делаю еще две последовательности - ключей и офсетов. Загрузка и вычисление индекса выполянется 1.8 сек. А скорость выборок 110 мс. на 10 тыс.

Переделал тест на использование UniversalSequenceBase. Загрузка 1.2 сек. или несколько больше. 

### 20181228 11:13
Действительно подтверждено, что те действия, которые я выполнял с UniversalSequence можно выполнять и с базой. А в UniversalSequence дополнитлеьно есть только параметризация, пара функций и мало полезный public object GetAny(long start, long number, T key). Почему малополезный? Потому что по модели выявления оригинала, нужно выделение всех, а потом фильтрация.

Теоретически, все эти "штучки" можно объединить в один класс. Но чтобы этот класс был полезным, надо ограничить возможность выхода на сложные ошибки. Создание экземпляра, равно как подсоединение к экземпляру, выглядит надежной группой действий. Clear() - да, Flush() - да. AddElement() - тоже похоже "да". И даже сканирование Scan(), также выглядит достаточно надежным действием. Эффекты синхронизации я пока не понимаю...

Попробую пойти по пути, намеченному в Polar.CellsIndexes. Можно даже позаимствовать имена, только в другом пространстве имен.  

Начал что-то создавать и "уперся" в абстракцию индекса. Ну чтобы интерфейс специфицировать. 

### 20190101 09:22
С Новым годом! Что-то концовка года была нервная, но теперь есть неделя (8 дней) на то, чтобы поработать. 

Начну с уже продуманного. Оказалось, что не видно способа избавиться от признака deleted в опорной таблице. Действительно, общая форма выборки - это:
```
sequence.Where(e => P(e)).Select(e => F(e))
```
Чтобы проводить фильтрацию и функциональное преобразование, надо делать качественное сканирование. А при сканировании мы должны выделять только "действующие" элементы. Другого эффективного способа кроме вставления признака deleted как-то не получается... Похоже, признак и отметка времени являются не альтернативными свойствами, а дополняющими. Признак важен для сосредоточенной части модели, а отметка времени - для распределенной. Вернусь к модели.

Итак, есть набор элементов одного типа. В этот набор можно добавлять элементы, Элементы можно сканировать, т.е. перебрать по очереди все элементы. Вот сканирование подозрительно в контексте множества совпадающих по ключу элементов в разных сегментах.
На элементах определены функции key(e), mT(e), isnull(e), deleted(e). Элементы с признаком deleted считаются уничтоженными и не участвуют в выходных выборках. Элементы с одинаковым значением key(e) считаются "одинаковыми" и правильным представителем является элемент с максимальной отметкой времени mT(e). Элемент с истинным isnull(e) соответствует "совсем" уничтоженному элементу.

Насчет сканирования я подумал. Замечательным свойством может быть, когда ключи элементов "распадаются" по сегментам. Тогда не требуется дополнительного сведения одноключевых элементов. В этом случае, отметка времени не нужна! Но если это свойство не соблюдается, то как-то плохо...

Причем плохо во всех вопросах. Работа с множеством пересекающихся сегментов может выполняться через кеширование данных. Если имеется ситуация внешних сегментов, то можно делать запросы к этим сегментам и множества результатов накапливать в кеше корневого сегмента (хранилища). То есть, если айтема с заданным ключом нет в кеше, он запрашивается везде, где он может быть и помещается в кеш. Надо все это внимательно обдумать. 

### 20190102 10:13
В общем, откладываю идею "настоящей" распределенности, т.е. распределенной системы сервисов, и начинаю сосредотачиваться на сегментном решении.

Придется вернуться к варианту UniversalSequence, наследуемого от базы. Так раньше "работало", надо посмотреть новый вариант. Универсальная последовательность - структура прямолинейной реализации. Просто последовательность. Есть ключ, есть другие оговоренные свойства и функции. Но как же делать простейший Fill()? Просто "бездумно" пишем поток элементов в последовательность (это надо для скорости). Видимо так, но потом придется возвращаться к этому потоку. Мы вычислим ключевой индекс. Ключевой индекс даст нам совпадения. В предположении, что совпадений мало, мы можем по каждому совпадению, не являющемуся оригиналом, сделать специальную отметку unused. Другие индексы не будут влиять на опорную последовательность. Как-то я об этом не думал раньше...

Появляется еще один вопрос о технологичности нахождения оригинала. Индекс содержит массив офсетов и, в лучшем случае, ключ или полуключ. Проходить весь массив офсетов, прыгая по последовательности, кажется слишком затратным. Итак - только ключ или полуключ! А вот простой индекс может быть и view-ориентированным. 

### 20190103 09:36
В уме я все расчитал, надо эти мысли "положить на бумагу". Если коротко, что универсальная последовательность очень проста: это последовательность и набор индексов. Набор индексов отрабатывает действия, проводимые с последовательностью. 

Промежду делом, провел простенький эксперимент с текущим (быстрым) вариантом ключевой последовательности. Я заменил файл на MemoryStream. Загрузка выполняется приблизительно столько же, а выборки - раз в 6 быстрее - 10 мс. на 10 тыс. А если избавиться от бинарного поиска, то будет 34 мс. на 100 тыс. выборок. Вполне прилично... Есть к чему стремиться!

Вернусь к постепенному формированию универсальной последовательности с индексами. Строю одну последовательность и один ключевой индекс. Пытаюсь все сделать правильно. 

### 20190104 07:41
Двигаюсь очень медленно. Но двигаюсь. Кажется...

Сейчас поизучаю вопрос буферизации. Дело в том, что пишется два потока. Вроде все нормально - это два файла, но как-то нет уверенности, что с кешированием все в порядке. 

2 файла заполняются 4.5-4.8 сек. Один - 2.8-2.9 сек. Вроде так и должно быть. Подозреваю, что буферизовать нужно при работе с одним файлом и несколькими потоками. 

Под конец дня понял, что я неправильно структурирую решение. Наиболее простое решение - один класс, напр. Sequence и сразу в конструкторе указаные индексы, указаны в виде массива разных классов, имеющих интерфейс IIndex. Что-нибудь вроде:
```
Sequence usequence = new Sequence(tp_element, stream_gen, 
    new IIndex[] 
    {
      new IndexKey(keyProducer, stream_gen),
      ...
    }
);
```
Причем IndexKey - это уже динамический индекс. Простая последовательность будет отрабатывать добавления и изменения элементов, а индексы - доступ к элементам. Нулевым членом в последовательности может быть или должен быть основной ключевой индекс. Он может быть или IndexKey или IndexHalfkey. Неключевой индекс IndexView используется когда нет ключа, напр. для поиска по имени. Еще в обойме индексов должен быть секторный индекс, но по его поводу я задумаюсь позже. 

### 20190105 11:44

Есть одна "загвоздка" - нет схемы управления стримами. Например, надо разделить стримы на группы или что-то поддержать кешевым решением и др. Еще одна скрытая "загвоздка" заключатся в том, что и порождение стримов и подключение к стримам осуществляется с помощью одного генератора. Рассмотрим отдельно эту проблему. Некоторым базовым представлением является уже сформированный набор стримов с заданными свойствами, тогда остается только подставлять следующее значение в следующее использование. Все бы ничего, но мы на стадии конструирования универсальной последовательности не очень представляем предназначение тех или иных стримов. Более того, схема, как и базовая, (сильно) зависит от порядка использования стримов в процессе разворачивания, а он может различаться по создании стримов и при их использовании. Итак, что можно сделать?

Оставлю этот вопрос на будущее. В конце концов, я могу подобрать нужные стримы в вектор и организовать из него генератор. Попробую написать код. 

Что-то написал, пока очень мало. Можно сказать, что сообразил, что управлять стримами возможность имеется. Действительно, в приведенном примере описания объекта usequence, генераторы стримов могут быть разными и управление ими ведется в общем контексте. Так что продолжу. 

Сделал последовательность с одним ключевым индексом. Вычисляется 2 файла, вроде нармальных размеров. Надо попробовать что-то прочитать. Время формирование последовательности и индекса 4.5 сек. для 10 млн. элементов. 

### 20190106 11:46
НА чем я вчера застрял. Вообще-то на том, что надо реализовывать сортировку и бинарный поиск. Некоторой альтернативой стало то, что ключевой индекс, как и некоторые другие, можно реализовывать и как последовательность записи, состоящей из офсета и ключа или как пару последовательностей офсетов и ключей. Решил, что пока идейнее будет реализовать классический вариант - одна последовательность записей. Сами действия можно поместить в  UniversalSequenceBase. Попробую, там еще проблемы с типом ключа ожидаются.

Что-то не очень хорошее произошло с размером индексного файла f2. Его размер 198 888 898 байт.
А должно быть 10 млн. * 12 байтов + 8 !!! 

Выяснил. Просто за счет иерархии построения, f0 оказался индексом, а f1 - опорной таблицей. 

### 20190108 02:58
Вчерашним днем юбыл занят изучением диссертации Артамоновой. Теперь уже ночь и вообще наступили новые сутки...

Я не закончил делать индекс, а надо бы. Надо сделать универскльное ключевое решение, а потом специализированное. Начну с универсального. 

Сортировка вроде заработала, но скорость существенно хуже, чем была. Сейчас она 8.5 сек. Секундочку... Похоже, все не так плохо. Я изменил режим компиляции на Release и получилось 4.8 сек. и даже в одном из пропусков 4.5 сек. Наверное память расходуестя изрядно... Попробую увеличить количество элементов. Увеличил до 100 млн., все сработало, вроде бы, и за 64 сек. Только я не понял что творится с использованием ОЗУ. Попробую перезагрузиться в запустить на более "чистой" машине. 

200 млн. - 170 сек.
400 млн. - 323 сек.
800 млн. - не хватило дискового пространства, провожу эксперимент на рабочем компьютере

800 млн. элементов на набочем компьютере обрабатывались 1877 сек. Похоже, это уже на грани. Попробую 400 млн. - 895 сек. 

### 20190109 07:51
Забавно, но построение базы данных на рабочем компьютере выполняется заметно медленнее, чем на более слабом домашнем. 100 млн. элементов строятся 86 сек., 128 сек., 113 сек. А 200 млн. - 445 сек. Странно.

Я остановился на том, что мне нужен бинарный поиск в индексированной последовательности. Для простого случая, с которым я сейчас работаю, надо из индекса сформировать поток офсетов всех элементов удовлетворивших кортерий совпадению ключей. 

### 20190110 10:32
Наконец, сдела бинарный поиск. Удалось его променить. На рабочем компьютере 10 млн. записей загузились за 9 сек., 10 тыс. выборок по ключу выполнялись 1100 мс. То есть, раз в 10-20 медленнее, чем при использовании специального индекса или без оного. Собственно, результат ожидаем. По и дихотомии, 10 млн. точек делятся пополам приблизительно 23 раза. А каждое деление - это обращение к диску или кешу диска. В данном случае - к кешу, поскольку на "чистой машине" запросы выполнялись бы раз в 1000 медленнее.

На домашнем компьютере этот же текст показал также 9 сек. на загрузке и также 9-11 сек на выполнении 10 тыс. запросов. 

Перешел на работу, теперь изменения будут проводиться только рабочего компьютера. Пропуск стандартных 10 млн. записей дал время щагрузки 8.8 сек., но вото 10 тыс. выборок по-прежнему несколько больше 1000 мс. Теперь надо попробовать запустить без загрузки. 

Сечас пропустил тест на 100 млн. в режиме отладки, получилось 198 сек. загрузка, использовано 13.6 Гб., 236 сек. / 10 тыс. выборок.
В рабочем режиме, получилось загрузка 158 сек., выборки 236 сек.
Без загрузки, выборка получилась 56 сек. Так что между 10 и 100 гигабайтами, есть предел для данной схемы и 16 Гб. ОЗУ. Буду проводить эксперименты на 10 млн.

Надо попробовать переход на линейное сканирование при определенных разменах сегмента (start, number). Попробовал, эффекта не получил. Вроде на группах порядка 100 элементов, небольшое улучшение чувствуется (не факт!), так что посталвил константу 100. 

Следующий эксперимент - запросы без загрузки и после перезапуска компьютера. Получилось 29 сек. / 100 запросов. Прямо точное "попадание" в вычисленное значение 100 * (10 мс. диска) * (24 раза обращение к диску за индексом и элементами).

Теперь надо добавлять шкалу.  

### 20190216 11:29
Рваный ритм моей нынешней жизни мешает, сильно мешает, сконцентрироваться на работе. Вот она и почти не двигается. Начал делать интерефейс Тургунды без View и Razor, но не доделал, потом поставил эксперимент делания сервиса - не доделал, потом сделал пототип JavaScript приложения - и опять не доделал!.. С чего начать? Главный "долг" перед пользователями - отсутствие новой версии пары редактор/вьюер, применительно к Открытому архиву.  Попробую поработать в этом направлении, тем более, есть что поодолжать. 

### 20190219 07:30
Я вчера вышел на то, что лэйаут нового решения не соответствует старому. Надо привести в соответствие. 

Продвинулся совсем чуть-чуть. Застрял на вычислении внутреннего формата. Например, Раскрываем запись. Ее формат задается и здесть вариаций нет. В записе есть поля, прямые ссылки и обратные ссылки. Прямые ссылки могут иметь варианты по типу записи элемента, куда ведет ссылка. Например, из отношения reflection ссылка in-doc может вести и в прото документ и в фото-видео-аудио. Надо проверять. То же самое, может быть и с обратными ссылками. Но там можно наладить безальтернативность. На всякий случай, стоит вычислять подформат по принципу: пройти direct или inverse, взять элементы record и взять тот, тип которого имеется в данном подзначении. 

### 20190220 11:29
Вчера "уперся в стенку". Выяснилось, что у меня какие-то проколы в семантике моей шаблонной системы. Или я что-то важное забыл... Проблема в альтернативах по типам и струкутрам записей. Шаблон диктует некоторое иерархическое построение выбранной части графа. Это построение видится в виде специального вида таблиц. Есть даже таблца с одним рядком... Проблема в том, что если есть альтернативные типы и соотвествующие им шаблоны, то непонятно что надо делать. 

Действительно, пусть есть запись и шаблон для этой записи. В шаблоне указываются поля, которые надо визуализировать в виде таблицы. Множественность вариантов полей пока опустим, будем считать, что есть только один вариант значения для каждого из полей, упомянутых в шаблоне. Определенность присутствует. Теперь рассмотрим прямые ссылки. Ссылаться по одному отношению запись может на другие записи разных типов. В шаблоне перечисляются варианты типов.  

Я до конца не понимаю ситуацию, но сформулировал некоторое предположение. Предположение заключается в том, что исходящая ссылка не предназначена для какого-то немедленного табличного оформления. Она лишь превращается в строку с гиперссылкой. А вот нажатие на гиперссылку возвращает ситуацию к стандартной, когда есть тип и есть значение записи и можно формировать каноническое представление. 

А вот в обратную сторону, в сторону inverse, вариантов быть не должно. Иначе трудно строить обратные таблицы. Посмотрю на текущий профиль или профили, используемые в Тургунде. Посмотрел. Вроде везде имеется единственность записи под направлением inverse, а под направлением direct есть варианты (по гео и документам).

Некоторая тонкость заключается в том, что "строковое" гиперзначение нужно делать на основе самостоятельного (другого) формата, а его пока нет. Но мы можем воспользоваться "стандартным" форматом:
```
<record type="системный объект"><field prop="name"/></record>
```
Даже не буду выписывать это решение, внесу его прямо в код. Удивительно, но именно это решение ранее было реализовано. Так что дело не в прямых ссылках, а в обратных отношениях. Проверил обратные отношения, вроде также правильно сделано. Попробую двигаться дальше. 

### 20190221 08:03
Я остановился перед критерием того, что нужно или не нужно использовать компактные представления или табличные представления. Ситуация связана с визуализацией группы обратных отношений, соответствующих одной обратной дуге. "Короткие" отношения sys->sys, типа "отец или мать", я уже давно не рассматриваю. Рассматриваю только псевдосущности. Если псевдосущность, то...

### 20190222 08:07
Вчера "запустил" демонстрацию фоток и пошел спать. По идее, "иконная" система должна обладать следующими свойствами: В режиме largeicons изображается некоторый имидж вместе с некоторой подписью. Если тип айтема photo-doc и есть поле uri, то изображение будет браться из этого uri. Иначе, а качестве имиджа будет взята дофолтная для типа иконка.

Уже сделал и фотодокумент. Правда был озадачен тем, что в старом переработанном массиве данных SypCassete, для всего есть только medium-размер. Это можно попробовать регулировать с контроллере Docs. Если нужен normal, а есть только medium, вставлять medium и наоборот. 

### 20190223 08:48
С Днем защитника Отечества! Я себя в достаточной мере ощущал и ощущаю защитником. Обучался, присягу принимал, сборы проходил, занимался критическими для страны технологиями, взаимодействовал с ВПК, обучал и обучаю студентов, школьников, аспирантов. Вот!

Такой мелкий вопрос как где разместить переключатель режима визуализации "панель/таблица", я не смог сраду ответить. Потом задумался об общих моментах, о пользовательских параметрах, о пользовательском состоянии (сессии). К этим вопросам можно будет вернуться позже, а пока сделаю переключение по-проще. Для начала попробую поместить его в переменные класса HomeController и посмотрю что получится. 

Вроде получилось и вроде смена состояния не мешает другим пользователям. Правда состояние "не держится" при уходе в каком-то стандартном направлении (без указания моды), но это мелочи. 

Итак, что надо сделать? Для оценки этого, попробую запустить новое решение на машине gea.

### 20190224 08:32
Уже четвертый день подряд начинаю работу в одно и то же время! С утра имеется энтузиазм, а потом он затухает. Вчера затух на задаче перехода к редактированию. Можно сказать, на авторизации. Можно сразу "окунаться" в cookies, а можно сделать сначала другое решение. Это состояние пользователя. Состояние закодировать строкой и передавать строку от вызова к вызову. В состояние можно "затолкать" имя пользователя, роль и т.д. 

Состояние не получается хранить оперативно, но можно передавать от одного кадра к другому. Состояние можно разбить на пользовательский код и собственно состояние и вторую часть хранить в базе данных. Или в cookies. Или можно попробовать сохранять состояние в сессии. Попробую этот последний вариант.  

### 20190227 09:29
Опять несколько дней не работал. Немудрено: 25-го заседание суда, 26-го Петя приходил... Я во многом работаю "по инерции" - дела двигаются "черепашьими" шагами, цель не достаточно определена, какая-то существенная часть дел или игнорируется или откладывается... Попробую сделать еще парочку шагов. 

Я уже сделал некоторое состояние сессии пользователя. На него можно "навешивать" специфические функции. Начну с авторизации. Потом можно вернуться к редактированию. Надо сделать запрет уничтожения и выход из уничтожения основной записи. Потом настанет пора собственно редактирования. Потом - добавление записи или отношения. Есть чем заниматься!

Авторизация. Попробую сделать как раньше. Только в одном экране. 

15:41

Боже, как медленно!.. Медленно соображаю, медленно работаю. Наконец, сделал авторизацию. Теперь сделать уничтожение, точнее, запрет на уничтожение. 

Вроде сделал. Теперь собственно редактирование. Попробую сначала выделить рядок для построения новой таблицы. В этот рядок надо разместить таблицу из двух колонок. Как-то так... Вспомнил. Рядки идентифицируются идентификатором соответствующей записи. Идентификация идет eid=... Так идентифицированные рядки должны строиться по-другому. 

### 20190228 15:52
Сегодня день рождения Пети! 36 лет!

Застрял на "собственно редактировании". Надо решительнее брать эту крепость. Один из вопросов заключается в том, что набор имен параметров для обработки заполненной формы может быть фиксированным, но тогда это что-то вроде 1, 2, 3... или нефиксированным. Тогда есть нибольшие проблемы работы с этими параметрами. Проблемы я знаю как преодолевать, это напрямую "лезть" Request и там получать. Напр. так:
```
var v = HttpContext.Request.Form["comm_chk"];
```
или через перечисление, типа:
```
  HttpContext.Request.Form.Where(kv => kv.Key[0] == '_');
```
или через формат, обрабатыать поле за полем, прямую ссылку за прямой ссылкой.

### 20190301 08:50
Первый день весны, ура!

Я несколько застрял в мыслях о том, как реализовывать редактирование. А еще - как сделать AJAX-решение по редактированию. Пока AJAX я не внедрял, но я и сделал немного. А можно ли сделать общее AJAX/noAJAX решение? Как все это выглядит. Начну с гиперссылок. Пусть есть некоторая гиперссылка, которая приведет к локальному изменению формируемой картинки. Есть базовая картинка B и есть добавление A. По нажатию гиперссылки контроллер вырабатывает A и B и внедряет A в B. Если используется AJAX, то по гиперссылке, передается команда с параметрами, а сервис формирует только A. A внедряется в B уже средствами JavaScript. Команда обращения к сервису можно делать средствами HTML или JavaScript. Если делать средствами JavaScript, то потенциально появится возможность плавного перехода на AJAX-решение. Как-то общая схема не вырисовывается... Продолжу делать noAJAX.

### 20190302 13:41
Сегодня заметно продвинулся - сделал вывол перечислимых. Теперь надо сделать фиксацию записи. Потом можно будет заняться прямыми ссылками и создание новых сущностей и отношений. 

С отказом cancel было просто: бросаю все и делаю редирект на портрет с нужным идентификатором. А если надо зафиксировать? Тогда надо собрать запись и послать ее движку для фиксации. Остается вопрос со скрытыми полями. Действительно, если формат упрощает какой-то тип записи, то что означает новая запись с отсутствующими поляма, которые ранее были в записи? Можно новую запись формировать по имеющемуся шаблону. Можно воспроизвести какие-то поля сделав специальный запрос. Там могут быть не только другие поля, но и языковые варианты полей. 

Вообще, с языковыми вариантами, я давно нахожусь в тупике. Схема, существующая в XML и RDF как-то плохо сочетается с введенными записями и табличной визуализацией. Вроде я не отменял языковые варианты, но их мало что поддерживает... Посмотрю что у меня было сделано ранее. 

### 20190303 06:31

Вышел на свои ошибки... Похоже, несколько. Попробую сразу исправлять. Первая - юзер не "стирается" в окне статуса. Исправил. Вторая ошибка в том, что неправильно визуализиретса перечислимое поле. Я это уже делал! 

Кое-что исправил. Теперь остановился перед сохранением результата. В принципе, формат при формировании запроса к PutItemToDb не требуется. Да и тип требуется только косвенно. Попробую собрать элемент из того, что есть. Пустые поля не включаю. 

Возникла загвоздка: без формата из передаваемых параметров трудно извлечь поля и прямые ссылки. Есть некоторое количество решения этой проблемы. Важно, чтобы было качество... Так вот, можно все же передавать формат, можно имена полей и ссылок как-то синтаксически отмечать, напр. ставить вначале подчерк. А можно собрать XML-сборку и передавать сервису. Последнее, правда требует Javascript-программы. А еще можно по типу записи найти "нормальный" формат и работать с ним. Похоже, последний вариант имеет преимущества. Попробую.

Начинает работать. Есть недоделки и проблемы. К недоделкам отнесу редактирование связей. К проблемам отнесу то, что плохо работаю в пространстве элементы - пространства имен - языки. К этому добавляются проблемы наложения данных, пусьые элементы и т.д...

### 20190304 07:00
Кажется, все не так плохо. Пришла пора сделать более качественное редактирование записи. Семантика редактирования такова: 
1 Создание нового фог-документа предполагает немедленное внедрение в его корень нужных пространств имен.
2 Добавление записи - базовая операция
3 Добавление записи "маскирует" предыдущие записи с данным именем. Определение оригинала ведется по временной отметке mT.
4 Уничтожение записи делается тем, что добавляется запись с тегом delete и нужным идентификатором rdf:about. Временная отметка обязательна. Уничтоженный элемент может быть снова сделан сущесвующим через добавление новой записи. 
5 Изменение записи делается добавлением элемента с тем же идентификатором. Есть текущий вариант записи, есть добавление, есть новый вариант записи.  В режиме "накапливания" рекомендуется новый вариант записи формировать из текущего и добавления по следующей "стратегии": а) поле уничтожается если в добавлении есть явное присутствие этого поля с пустым содержимым (этот пункт сомнителен); б) поле добавляется если нет такого языкового варианта, если есть - этот вариант изменяется на новый; в) языковый спецификатор имеется лишь у текстовых полей; в добавлении языковый спецификатор может отсутствовать (???), тогда будет подразумеваться дефолтный (откуда его брать?).       

Программа работы намечена, но можно не торопиться. Пока все и так работает. Надо разобраться с прямыми ссылками. 

Все же пришлось добавить языковый спецификатор в редактирование. Иначе, при одном имени записи, получалось две (одинаковых) ссылки на нее при текстовом поиске. Следующим шагом будет управление (текущим) языком.  

А что теперь? Теперь хотелось бы начать создавать новое. Новые записи, напр. Начало есть. Теперь подумаю как вводить новые отношения. Наверное, похожим образом. 

### 20190306 08:24
Пытаюсь пораотать в Москве. Это очень сложно по условиям и по здоровью. Я умудрился приболеть, нос плохо дышит, иногда чихаю, голова болит...

Тем не менее, я сделал формирование нового отношения. Теперь надо научиться делать прямые ссылки. А как это делать? Я уже задумывался, отчетливого решения пока не нашел. Напомню, что я пока пытаюсь обойтись без AJAX'а. Итак, есть кнопка "проверить", скорее всего, именно эту кнопку надо задействтвать. Для начала, мне нужна какая-то форма визуализации прямых полей. Если прямое поле есть, то все очень просто. Вот это "просто" и надо сделать, для начала.

Если прямая ссылка уже задана, надо изобразить ее в виде гиперссылки (имя + URL). 

### 20190308 05:08
Сегодня остаточно сложный деньдля мужчин, когда надо как-то, хотя бы частично оправдать ожидания близких женщин... Но пока есть возможность, постараюсь поработать. Я застрял на непростом месте - на редактировании прямых ссылок (отношений). 

Какая логика того, что задумано? Есть портрет сущности, есть отдельные записи, представляющие либо главную запись сущности, либо записи обратных отношений. Мы умеем эти записи добавлять, уничтожать и редактировать. При редактировании, мы умеем устанавливать или менять значения полей. Но пока нет средств для добавления, уничтожения, изменения ссылок. Сразу скажу, что полных набор редактирования ссылок не предполагается, предполагается реализация лишь добавления ссылок. А редактирование делается через удаление. А удаление делается посредством уничтожения записи, с последующим созанием новой записи. Такой подход неплохо годится для отношений, поскольку на отношения никто не ссылается. Для основных записей сущностей подход также годится, но может быть излишне громоздким и не технологичным. Например, редактируем какую-то персону и нам нужно изменить прямую ссылку на отца. Для этого, нам нужно уничтожить запись о персоне, ввести новый вариант записи о персоне и там проставить новое значение ссылки. Для уничтожения записи, надо сначала уничтожить все ссылки на эту запись. Это и прямые ссылки из других сущностей, напр. то, что персонаж является, в свою очередь отцом для кого-то и обратные отношения. Если мы не хотим потерь в данных, нам предстоит огромная работа! А между тем, действие по редактированию выполняется изменением всего одного атрибута rdf:resource в записи...

Вернусь к редактированию ссылок. Продолжаю описывать логику построения. Режим редактирования записи "запускается" указанием eid - идентификатора записи. Соответственно, это может быть либо главная запись портрета и тогда eid==id, либо запись обратного отношения и тогда eid!=id. "Рисует" редактирующую панель базовая процедура построения таблицы. 
```
private XElement Htable(IEnumerable<XElement> xrecs, XElement format, string cla, string eid, string bid, string iprop);
``` 
Здесь указывается множество "рядков" таблицы, формат записи для рядка, како-то класс визуализации (хорошо бы от этого избавиться), идентификатор редактируемого рядка (записи), базовый идентификатор bid соответствующий тому id, который фигурировал при построении портрета, iprop - обратное свойство по которому группа записей прикреплена к портрету. 

Вот эта процедура и строит или основную таблицу или таблицу отношений. Если среди рядков находится рядок с индентификатором eid, то этот ряд отрисовывается особо в другом виде и в коде фрагмента появляется форма. Соответственно появляется возможность выхода из кадра через одну из трех кнопок. По кнопке "отм." происходит отмена eid и, соответственно, следующее построение портрета будет без формы редактирования. По кнопке "сохр.", накопленные поля сохраняются в базе данных. Третья кнопка "пров." - проверить, имеет более комплексное продолжение и работает только когда есть потребность в добавлении ссылки куда-то. Эта кнопка "реагирует" на наличие данных в специальных полях формы linktype и linkname. В этом случае, снова запускается построение портрета P и в портрете, в форме редактирования и в том поле прямой ссылки, где набиралось имя объекта ссылки, появятся варианты в виде гиперссылок. А вот нажатие на гиперссылку приведет к проставлению ссылки на либо существующий объект, либо объект сначала создается, а потом на него устанавливается ссылка. 

### 20190309 03:31
Как бренен мир... Вчера узнал о смерти Ирины Заниной - и трагично и крайне неожиданно. 

По поводу проекта, я сейчас в раздумиях. Что-то получилось логически сложновато и я запутался. Наверное, можно и распутаться, но почему так сложно? Можно попробовать написать спецификации сервиса и редактора. А может, я пошел не по тому пути и вместо эффективности, будет получена неэффективность. И все же надо доделать то, что делал. 

Продолжаю работать. Кажется, до выставления прямых ссылок осталось не так много.

20190312 04:39
Прошло три дня, жизнь продолжается, работа не двигалась... Заседание суда опять отложили. Теперь до 4 апреля. В принципе, это соответствует нашим планам и интересам. Договорился, что в следующией раз приеду на один день и вечером же уеду. До 4 апреля будет еще заседание в Новосибирске 20-го, потом защита диссертации 21-го, может еще что-то забыл. Очень хочется на Алтай. Физическую форму я во-многом потерял и было бы хорошо нагрузить организм прогулками по Семинскому перевалу. 

Так что же у меня с проектом? Я застрял на фиксации внешней ссылки. Неужели это такая сложная проблема? Есть текущая запись eid, в ней надо прописать прямую ссылку на какой-то айтем, идентификатор которого уже известен или вычислен. Всего лишь rdf:resource с соответствующим предикатом. Некоторая путаница возникает по причине разных возможных представений айтема. Есть айтем в храниище, это нормальная rdf-запись, и есть айтем в косвенном представлении через <record id="" type="">...</record>. Выборку мы осуществляем в косвенное представление, а запись нового значения делаем в прямом. Есть еще выборка через специальный портрет. Надо посмотреть что вычислено именно в том месте. Посмотрел. Формально, там (уже) нет айтема или записи, там есть идентификатор айтема. 

Первая попытка поработать елалась слишком рано. Сейчас уже 9:30, можно снова вернуться к работе. Я заснул на размышлении создании связи. Тут есть "засада", заключающаяся в том, что общее редактирование записи, связанной с отношением, выполняется в два действия или даже в несколько, если ссылок не одна.

Тем не менее, придется двигаться в этом "двухэтапном" направлении. Сначала надо посмотреть на то, что порождает специальный портрет. Это может пригодиться. 

### 20190314 12:32
Редактирование заработало и все уже как-то выглядит. Пока рабочей режим без AJAX'а, можно думать о его внедрении, но это не срочно. Срочно доделывать. Есть несделанные или недоделанные моменты, которые нетривиальны. Надо писать план и начинать работу по его выполнению. 

Идея первого пункта или этапа в том, чтобы переработать сервис хранилища. Сейчас сервис "зацеплен" за методы в разных местах, по большей части в SObjects. Есть выходы и на...

20190315 10:34
Вчера поработать не получилось. И голова болела и что-то мешало... Но я все равно думал над следующей задачей. Действительно, надо делать хорошее хранилище и к нему - хороший сервис.

Что такое хорошее хранилище? Вроде бы RDF или RRDF (Recorded RDF), это лучший вариант. Это означет, что хранилище содержит либо триплеты, либо записи. А записи состоят из идентификатора, атрибутов, полей и ссылок. Почему такое разбиение? Для индексации. Нет индексации по атрибутам, разные индексы по ссылкам и полям. Но можно все в одной таблице. Два индекса. Или три. Или два вместе с двухэтажной сортировкой. 

Сначала, посмотрим на всю базу данных в целом. База данных состоит из фог-документов (или сегментов?). Фог-документ (или сегмент) может иметь владельца. Возможно, он также может иметь идентификатор. Сегмент - это набор триплетов. В этом наборе есть дополнительные триплеты: отметки времени, возможно и какие-то другие. Отметка времени:
```
<субъект> fog:mT "время" .
```
Эта отметка означает, что 
1) Помеченная так запись относится к категории темпоральных. 
2) Указано время фиксации данной записи. 

Оригиналом считается запись с более поздней временной отметкой. Некоторым ключевым вопросом является возможность сборки записи из частей, опубликованных в разных сегментах. Пока, будем считать темпоральность встроенной и неооторжимой от семантики хранилища. В случае хранения данных в сегментах в виде записей, то допустимо наличие нескольких записей с одним идентификатором. Оригинал - с более поздней временной отметкой. В случае сегментов в виде набора триплетов, запись может быть только в одном экземпляре. Это с точностью до тождественных триплетов, когда совпадают все его части: субъект, предикат и объект. В этом случае, у записи может быть только одна временная отметка, это отметка считается временем фиксации записи и конкурирует среди экземпляров записей в разных сегментах. 

Уничтожение записи производится через добавление еще одного системного атрибута  
```
<субъект> fog:deleted <несущественно> .
```
Это триплет означает, что запись имеет значение null. Это значение спровождается временной отметкой и действуют общие правила по определению оригинала. В частности, запись может быть "реанимирована" или заменена на другую.

Еще один системный атрибут "заведует" отождествлением (идентификаторов) сущностей:
```
<субъект> owl:sameAs <объект> .
```
Эта запись означает, что субъект и объект "сливаются" - можно все вхождения или субъекта или объекта заменить на альтернативу. 

### 20190316 07:01
Проблема заключается в двух аспектах. Первый - неясность семантики темпоральности этих механизмов. Второй - в сложности или неэффективности реализации. 

По поводу реализации. Предположим, таких отождествлений в базе данных немного. В принципе, можно построить таблицу имен, сопоставляющую имени сущности, имя "оригинала" сущности. Таблица либо дает переименование для сущности, либо дает отказ - информацию об отсутствии переименования. А если есть цепочка переименований? Или дерево? 

Вообще, надо бы создать стратегию/технологию внесения поправок отождествления в файлы базы данных. Некоторая проблема заключается в том, что идентификаторы сущностей могут "застревать" во внешнем мире, напр. в виде ссылок и требовать интерпретации. Еще один нюанс в том, что для эффективной реализации графовых построений может понадобиться таблица кодирования имен, наверное таблицы надо объединять. 

О чем сейчас идет речь? Текущее решение по хранилищу имеет два недостатка: тратит 2 Гб. ОЗУ и загружается секунд 15. Чтобы преодолеть оба, надо сделать все нужное аккуратно. 

Во-первых, база данных разделяется на набор fog-документов и на временное хранишище (ВХ). Главной базой является набор fog-документов. Временное хранилище загружается от основного и далее развивается синхронно основному. Это означает, что любое редактирующее действие выполняется и в основном и во временном. При этом, есть быстрый процесс старта временного хранилища. 

Наиболее сдерживающим разработку фактором, в последнее время, является колебание между кодированием и не кодированием строковых идентификаторов (URI). Кодирование позволяет более экономно использовать память, причем как дисковую, так и оперативную. Но логика работы хранилища усложняется при кодировании. И цепочка преобразований также удлиняется. Но с другой стороны, сложное задание можно сначала кодировать, потом исполнять, потом декодировать результат. Тут и экономия на трафике может быть заметной. Кроме того, на кодовую таблицу можно возложить еще и функцию отслеживания эквивалентностей. 

Пока незыблеммой остается реализация фог-документов. Можно даже важные изменения сделать именно в них. Первое - не надо записывать пустые поля и пустые ссылки. Второе - если местом записи является документ, в котором считывалась запись, надо эту запись ЗАМЕНИТЬ! Это вместо копировани. Посмотрю код.

### 20190317 06:43
Кажется, правильным решением является следующая двухуровневая система. Есть фог-документы, причем не все из них редактируются. Соответственно, вовлекается в "горячее" построение лишь малое их число. Все указанные фог-документы, используются для формирования временного хранилища. Временное хранилище и активные фоги составляют оперативную зону редактирования. Вопрос - как это все организовать?

Начнем от использования. Базовые действия: взять запись по идентификатору и искать записи по текстовому образцу. Это выборки. Временное хранилище будет выглядеть как набор записей. Временная отметка не нужна. Чистое key-value. Пришел ключ, получили запись. Индекс по имени строится на основе функции, задающей по записи ее имя или имена. Возможно, это будет векторный индекс. Это с учетом языковой и прочей множественности. С алиасами поступаем просто: есть записи naming, в них есть поле alias, оно функцией и определется. Множество других форм имени, напр. раздельное ФИО, обрабатываем также. Видимо, это будет векторный индекс. Теперь будем редактировать. Новое значение организовать легко. Для этого надо сформировать это значение и пометить его в доступный для данного пользователя документ. И надо поместить новое значение во временное хранилище. 

Как делать изменение? С точки зрения ВХ, все просто: заменяем сторое значение на сформированное новое. Эта методика разработана для key-value. С точки зрения фог-документов, также все не слишком сложно: надо в документе, доступном для редактирования данному пользователю, найти запись с соответствующим идентификатором и заменить ее. Если таковой нет, то просто добавить. Но нужно добавить временную отметку. Уничтожение делается полностью аналогично.

Вышел на создание хорошей базы данных и не смог... Хорошая, это в рамках проекта Universal, а он оказался недоделанным. Есть два пути: доделать или воспользоваться пакетами Polar.Cells и Polar.CellIndexes. Для проверки работы решения, попробую второй. 

Попробую повторить тезисы, связанные с "правильной" key-value последовательностью. Это есть последовательность типизованных элементов, она обладает следующими свойствами:
1) Есть функция ключа, вырабатывающая значения какого-то определенного типа. Заданному ключу или не соответствует ни одного значения в последоваетлности или ровно одно. 
2) Семантика добавления, уничтожения, изменения: если новый ключ не совпадает с существующими, происходит обычное добавление, если существует, то происходит замещение старого значения новым, уничтожение делается замещением старого значения с признаком isnull (или deleted).
3) Если нам надо делать сканирование элементов, то при замещении элемента, нужно отмечать его как isnull. И соответственно, при сканировании - проверять признак.
4) На элементах последовательности возможно определить произвольное количество ИНДЕКСОВ. Скалярный индекс - это функция, ставящая в соответствие элементу какое-то значение. По одному на элемент. Неполный индекс - скалярный индекс, часть значений которого не определена. Векторный индекс - функция, сопоставляющая элементам произвольное количество (ноль или более) значений заданного типа. Индексная функция используется для построния индексной структуры (индексного массива), которая помогает реализовывать обратную функцию, т.е. по заданному значению индексной функции определять множество элементов, которые на которых это значение достигается. Еще могут быть монотонные индексные функции, это напр. при лексикографической сортировке. 
5) Индекс может быть построен в любой момент (одномоментно). Построение индекса - не слишком "дешевая" операция и, как правило, включает в себя сортировку. Поэтому, для изменяемых (редактируемых) данных реальный индекс состоит из статической части, собственно массива и динамической части. Статическая часть индекса соответствует состоянию индекса на определенный прошлый момент времени. Динамическая часть - прямое отображение множества значений в записи. Для биекции (ключ->значение - взаимно-однозначное отображение), динамическая часть задается хеш-таблицей, кода значению ключа соответствует заначение (одного) указателя на запись. В противном случае, значению ключа соответствует набор указателей на записи.  
6) 

### 20190319 12:09
Пока просыпался, в голову пришла интересная мысль: а почему бы не использовать хеш-словарь временного хранения записей или значений индекса еще и как кеш? Например, запрашиваем по ключу элемент в последовательности. В индексе первичного ключа, находим офсет элемента, по офсету - читаем элемент и возвращаем его как результат запроса. При этом также можно сформировать пару (ключ, запись) и сохранить ее в словаре быстрого доступа. Только надо продумать как "чистить" кеш. 









