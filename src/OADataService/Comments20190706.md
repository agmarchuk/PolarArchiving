Для создания сервиса данных, я использовал шаблон Web Api. Предполагаю, что сдесь будет развернуто 
два сервиса: сервис доступа к документам и сервис базы данных. Сервис доступа к документам будет 
предоставлять документы для работы клиентов, напр. фотки, видео, аудио, плоский текст, XML, JSON. 
Соответственно, HTTP MIME ContentType будет: 
text/plain, text/json, text,xml
image/jpeg, video/..., audio/mp3

Тексты будут иметь кодировку UTF-8

Для начала, сделаю получение изображений. 


Другие документы (пока) 

### 20190707 08:31
Приехал на побывку домой и начал разработку. Еще вчера я пробовал делать контроллер документов DocsController. Суть контроллера - почти 
соответствует REST. Это хранимое множество документов разного типа. Думаю можно следовать идеям REST. В частности, доступ к хранимым 
документам будет выглядеть как-то так: 
http://domain.ext/OAData/docs/img - для выдачи всех
http://domain.ext/OAData/docs/img/uri - для выдачи одного

Кроме того, будет загружаться конфигурация. 
А еще будут загружаться и уничтожаться документы. Для некоторых действий понадобится авторизация. Авторизацию можно реализовывать с 
помощью кукиз. Но это - потом. 

Файлы могут быть любыми. Файловые сборки пока не поддерживаются. Специальный тип касается того, что выводится отдельно и, возможно, 
в подгружается браузером. Попробую pdf. ... Попробовал, работает. Буду действовать постепенно. Все начинается с конфигуратора. Создам 
класс Configuration и загружу конфигуратор. Пока никаких особых манипуляций с конфигуратором делать не буду.

Файл конфигуратора загрузил. Также сделал страницу по умолчанию. Потом можно будет к этой странице вернуться...

Теперь сделаю и загружу структуры помогающие доступу к кассетам и фог-документам.

### 20190708 13:16
Сделал ввод данных из кассет. Формируется массив информации о кассетах и другой массив информации о фог-документах. 
Надо будет сделать фиксацию проблем загрузки кассет и диагностику на диагностической странице. Вообще, пока нет 
концепции управления сервисом, надо будет разработать. Двинусь в сторону получения документа.

Теперь испытал последнюю из неопробованных возмжностей: получение документа. Все работает, хотя остаются вопросы. 
В частности, вопросом является как именовать полученный файл. Было бы замечательно этот вопрос унифицировать. Так,
чтобы у любого файла из архива, было уникальное имя. Может, что-то такое и будет. Напр. длинное имя можно сжать и 
превратить в какой-то идентификатор. Но так, чтобы по идентификатору, можно было бы восстановить uri документа. Пока
я на этом вопросе останавливаться не буду. 

Теперь надо сделать получение основных документов. В частности, фотки и фог-файла. Вообще, REST диктует иметь методы,
перечисленные выше. Все фотки выдавать нет необходимости, выдам одну. Попробую также научиться задавать дополнительный 
параметр. 

### 20190709 07:53
Попробовал, все получилось. Я затратил слишком много времени на адаптацию к идеям REST. В нынешнем варианте - не получается
У меня uri сформировано с использованием слешей, это мешает их использованию в конструкции типа http://domain.ext/OAData/docs/img/uri 
Попытка закодировать uri - пока не получается. В частности, использованию компрессора мешает малая длина. Из строки uri 
длиной в 32 байта можно получить после zip'а 144 байта, так что путь закрыт. Буду использовать нормальные параметры. 

Еще одна неприятность - в тестовой кассете SypCassete. Там нет типоразмера normal. Попробую посмотреть что можно сделать. 
Можно сделать специальный административный программируемый интерфейс и просто сделать фотки нужного размера из существующих.
С помощью LINQ-выражений. Пока его можно наметить в сервисе. Тем более, что именно там будут преобрабатываться документы.

В общем, поработал, но как-то не нацеленно... В частности, снова поискал способ работы с имиджами. Фактически вернулся к решениям 
базовой библиотеки. Пока такие решения меня удовлетворяют. Другие как-то даже не запускаются. Теперь сделаю небольшое продвижение 
к проекту. Декларирую метод котроллера:
```
```

Итак, я сделал основу сервиса данных. Он хранит важную информацию для быстрого доступа к данным. Он обеспечивает доступ к документам
по uri. Так что можно уже начинать обслуживать прикладные интерфейсы.

### 20190710 07:43
Можно и нужно продолжать. И я знаю в каком направлении. Мне нужен полноценный сервис данных. Он состоит из репозитория документов,
доступных по некоторому uri, и базы данных, предоставляющих данные по идентификатору. Возможно, еще и по формату. И репозиторий 
документов и база данных способны к добавлению и изменению данных. Изменения в базе данных первично, поскольку его можно выполнять 
не меняя структуры репозитория. База данных формируется из совокупности всех задействованных фог-документов. Фог-документы содержат
идентифицированные записи. База данных изменяется посредством добавления записей. Записи имеют отметку времени mT и более поздние
по времени записи "заслоняют" более ранние. Большая часть изменений в данных может производиться в динамике работы сервиса. Однако
есть еще и перезагрузка сервиса. Ее можно и нужно делать в определенных случаях. Во-первых, перезагрузку надо делать регулярно для 
того, чтобы не накапливались большие динамические структуры, связанные с обновлением данных. Во-вторых, есть действия с репозиторием
и данными, которые не воспроизводятся в базе данных автоматически. Например, изменение состава репозитория, "ручные" воздействия на 
репозиторий, ручные воздействия на записи данных. Система сделана так, чтобы вручную можно было бы сделать "все" не нарушащее 
синтаксическую структуру данных. И не нарушающее структуру кассетного хранилища. Но в будущем, набор "ручных" действий будет 
регламентирован и автоматизирован. 

Перезагрузка создает по-новой динамические структуры, помогающие осуществлять доступ к репозиторию и к данным. Динамическая структура
к данным, называется текущей базой данных. База данных, в общем случае, состоит из формируемой структуры записей и индексов. А также 
структур, формируемых в оперативной памяти. Есть более "легковесный" процесс запуска репозитория и базы данных, его можно назвать 
подключением. Это, напр. когда сервер перезапускался и надо запустить сервис. И есть более "тяжелый" процесс с формированием новой 
текущей базы. Этот процесс называем перезагрузкой и он может длиться довольно долго (сейчас секунды и десятки секунд, с ростом данных -
еще дольше). С точностью до завершения процессов записи в файлы репозитория, перезагрузку можно инициировать в любой момент времени.    

Пора приступить хоть к каким-то действиям. Попробую сделать загрузку базы данных. 

### 20190711 22:08
Так и не приступил... Вообще, голова тяжелая и медленная...

Сейчас уже понятно, что кусок 2019 года я в базу данных вряд ли сделаю в течение школы. Может после школы... Только кто будет описывать 
хотя бы фотографии? Буду думать о будущем. Сегодня решил, что одним из возможных вариантов испытания/использования сервиса, может быть
старая схема раскрытия айтема. Узел раскрывается на нулевом уровне - это просто запись. Следующий (первый) уровнень раскрытия включает
в себя обратные и прямые записи. Только надо блокировать прямые ссылки, соответствующие обратным ссылкам. Это как всегда. Но это - потом.
Сначала сервис. Сначала сервис без изменения данных. Это я могу написать легко. 

### 20190716 10:44
Время московское! Я уже в Москве и собираюсь на совещание с адвокатом. Пока я отказался продолжать работать в направлении Blazor - 
подожду когда технология устоится, когда будет больше примеров. Вроде я нащупал причину неработающего Http-соединения. Это какие-то
credentials. Наверное, это разрешения. Не буду тратить время и мозги на эти вопросы. Сейчас самое главное - сервис и перевод на сервис
старой тургунды. А может, и новой. С сервисо опять же есть много новых идей, но пока придется ограничить себя в этом творчестве. 
Но раз уж упомянул, коротко напишу про последнюю идею, это мне пришло в голову в самолете. Идея заключается в том, чтобы записывать 
новые записи дописыванием, а не как сечас новой записью всего фог-файла. Технически, это возможно, например перейдя к вариантам 
отдельных триплетов или записей. Но есть еще каунтер. Он в эту схему не учень укладывается. Есть несколько вариантов решения. Первый -
каунтер выделить в отдельный файл как у Пети. Второй - каунтер, как и другую мета информацию сделать специальной записью и постоянно 
переписывать, изменяя mT. Третий - каунтер не менять, пользоваться временной базой данных. В общем, есть над чем подумать. Пока я все
это отложу и буду реализовывать "старый" вариант. Когда фог-файл - это специфический RDF, когда у этого RDF-а есть специальные атрибуты,
главные из готорых - owner, prefix, counter. Кстати, можно было бы вообще отказаться от каунтера в пользу UID или использовать время в
качестве каутнтера. А что? Если брать миллисекунды, то десяток лет - это разрядов 42 в тиках, т.е. 36 символов. Что-то многовато. Может
округлить до секунд? Все, временно забываю!

Сначала репозиторий документов. Пусть он будет таким, каким его запроектировал Петя. Ну и мои добавления тоже не лишни. В частности,
параметры для вычисления фото и видео превьюшек кажется нужны. Хотя и не факт... У репозитория будет ряд методов доступа. Сначала - 
методы чтения. Каждый документ имеет свой uri и доступ к контенту документа выполняется по uri. 

20190717 04:33
Что-то не спится... Вернусь к разработке.

Какие документы мы можем хранить в репозитории и получать из него? Есть просто документы, можно сказать файлы, а есть специальные
виды документов. Набросаю доступ к документам:
```
/Docs/GetDoc?u=uri
/Docs/GetImage?u=uri&s=size (small, medium, normal или параметр отсутствует, тогда оригинал)
/Docs/GetVideo?u=uri
/Docs/GetPdf?u=uri
/Docs/GetXml?u=uri
/Docs/GetHtml?u=uri
```
Причем GetDoc является универсальным методом и через него можно получить оригинал документа любого типа. Попробую начать именно с
него. 

Первые два метода сделал и испытал. Хорошо бы сделать и испытать получение видео. Попробую, может получится. Только надо найти видео
в кассетах. Вроде что-то заработало. Потом еще проверю. Остались простые варианты, PDF, XML, HTML. Пока они не слишком актуальны. 
Это можно сделать потом. 

Теперь посмотрю что там у меня с базой данных, вроде работает...

### 20190720 09:47
Вот вернулся из Москвы, вчера все пытался переделать побольше дел, сегодня, в субботу, можно попробовать поработать. 

Я "застрял" на попытке сделать какой-то адаптер сервиса. Продолжу. 

И вот, к вечеру, могу сказать, что сделал Тургунду с опорой на сервис. Работает! Хотя и без редактирования. 

### 20190721 05:41
Попробую "по инерции" сделать и редактирование. Хотя бы оценю объем работы. 

Начну с Тургунды7. Там много эксперимента по "быстрой" генерации html страниц, но кажется, это не должно мешать. Там еще 
есть всякая "бяка" по сохранению состояния, но опять же это не должно быть помехой. Кажется... Дествую по шагам.

Шаг 1. Делаю пустую рабочую область. Нет загруженных кассет. Запускаю Тургунду 7. Сразу - облом. Я наделал некоторых изменений,
которыми приходится управлять непосредственно в коде. Это плохо, но надо работать. Привел в порядок, сумел запустить "пустое" приложение.
Авторизовался по существующей простой процедуре. Роли почему-то нет. Наверное, слишком все упростил... Попытка завести кассету
оказалась неудачной. Диагностика: "Кассеты может создавать только администратор". Надо смотреть код авторизации.

Что-то "закапываюсь", это не хорошо. Можно попробовать другой путь. Кассеты делать менеджером и сразу установить сетевую конфигурацию. 
Попробую.

Дело идет, хотя и как всегда, медленно. Исправил ошибку в сравнении с пустой строкой. Хотя может и не исправил, а вставил "костыль".
Опять застрял в раздумье о структуризации. В сервисе я разделяю хранилище данных и адаптер (контролер) базы данных. Хранилищ может
быть несколько, а база данных - пока одна и сформируется из всех задействованных в конфигурации (в конфигурациях) данных и метаданных. 
Меня волнует, что технически, база данных, точнее ее адаптер, подсоединяется полем к хранилищу или конфигурации. 

Итак, пусть требуется редактировать данные. В части именно базы данных, все достаточно просто - добавляется ТОЛЬКО один метод добавления
записи. Причем запись может добавляться с идентификатором или без. В последнем случае, база данных генерирует идентификатор. Запись 
приходит откуда-то, что после этого? В записи есть два добавленных извне системных поля. Это владелец и отметка времени.

Еще один вопрос периодически возникает: почему я выборки делаю через остовное дерево, а редактирование - напрямую, через запись. 
В принципе, можно сохранить формитное представление, напр. 
```
<record id="..." type="тип элемента">
  <field prop="свойство">значение</field>
  <direct prop="свойство" ref="ссылка" /> или
  <direct prop="свойство">
    <record id=""/>
  </direct>
</record>
```
Вообще-то мне приходится делать преобразование в неудобном месте. Можно добавить элементы <isnull/> и атрибуты mT и owner.
Или можно формировать запись из триплетов...

### 20190722 06:48
Отбрасываю сомнения, продолжаю работать. Во-первых, надо "докопаться" до вызова главной редактирующей процедуры.

### 20190723 07:27
Вчера кое-что сделал. Но, в основном, с утра. Потом занимался чем попало, потом устал... 

Я не могу сложить картинку сервиса. В части редактирования. Видимо надо реализовывать старую кортинку. В старой картнке нет 
распределенности. Соответственно, весь сервис это и репозиторий и база данных. Допустим, это так. Вот приходит запись через
PutItem(xrecord), где xrecord - расширенная полями owner и mT запись. По владельцу, мы выявляем fog-файл, годный для вставки,
если он еще не загружен, загружаем его, если нет идентификатора, то генерируем новый, изымаем владельца из записи, находим подходящий 
элемент и заменяем его или просто добавляем, сохраняем файл по месту, возвращаем копию сохраненного элемента. Посему бы так и не 
сделать?

20:25

Оказалось, что я не доделал хранилище триплетных записей, наверное как и траплетное хранилище. Нет слабой динамики. Все не так 
очевидно, поэтому придется восстанавливать рассуждения и логику. Итак (!), пусть есть последовательность записей. В принципе, все
записи в последовательности имеются, это начальный принцип. Далее, есть произвольное число индексов, построенных на какой-то 
начальный момент времени. И есть некоторый список добавленных к последовательности элементов. Это дублирование, но пусть будет так. 
Индексами "покрывается" некоторое предыдущее состояние. Для правильной индексации, нужно использовать динамический список. 
В принципе, дианмический список можно использовать сканируя и вычисляя соответствующие функции. Но, кажется, пока сделано не так.
Сделано так, что у каждого индекса формируется свой динамический список в форме, удобной именно этому индексу. И добавление элемента 
в последовательность приводит к запуску хендлеров в индексах. Надо посмотреть какие решения заложены в текущую реализацию хранилища. 

Все же удалось сдвинуться с "мертвой точки" - что-то стало работать в командах редактирования в связке клиент-сервис. 

### 20190726 07:05
Наступил отпуск, ура! Мы доехали до Семинского перевала и переночевали, сегодня определимся с нашими локальными планами. Потому что
основной план пока без изменений - доехать до базы Аксу на Джозаторе и там найти варианты активного и пассивного отдыха. Но можно ехать 
сразу и можно ехать подождав пару дней, кажется Лена склоняется ко второму варианту. А еще мы с ней заговорили о походе на Аржан. Но
это - потом. 

Я заканчил работу над программой на том, что редактирование начало работать в режиме сервиса, на с ошибками. Очевидной ошибкой является
непроставление где-то прямого отношения, старой неточностью является то, что пишутся пустые поля. Попробую восстановить ситуацию ошибки
и неточности. 

### 20190728 19:00
Сейчас я (мы), страшно сказать, на Джозаторе. Дорога была не так чтобы слишком сложной, но длинный и последний участок - гравийный. 
Наша Камри не любит таких испытаний. Но и шины выдержали и камни цеплялись по дну более или менее благополучно. 

Уже начал осваивать новые полевые условия для работы. Электричество есть, стол есть, интернета нету. Работать можно. Вчера я
запустил Тургунду3 на студии 2015. Правда "вылезла" проблема: простые действия по редактированию не производятся. И, как я
выявил, причина в том, что фог-документы якобы принадлежат пользователю mag. Причем эта принадлежность определяется не по 
содержимому фога, а по метаинформации в его документе. Как же все это работает в реальности? Я решил, что для моих нынешних 
целей это не существенно и стал вставлять сетевой адаптер. Но тот вариант сетевых вызовов, который у меня работает под Core,
почему-то не срабатывает под Framework. Интернета здесь нет, найти работающий вариант сетевых взаимодействий будет затруднительно.
С другой стороны, Тургунда7 уже заработала, в том числе, в режиме редактирования. Пока есть много нюансов, включая реагирование
на исключительные ситуации. Но в целом, это уже кое-что. Проведу некоторые эксперименты для уточнения ситуации. 

### 20190729 09:32
Провел эксперименты, внимательнее почитал диагностику, выявил следующее: отказ в сетевом взаимодействии происходит из-за
отсутствия авторизации. Техически, это вроде решается правильной установкой HttpWebRequest.Credentials. Пока нет интернета,
добраться до документации затруднительно, хотя я скачивал что-то. Посмотрел, там все про Core и Asp. Но эта проблема решаема.
Главное, что сервис работает вполне уверенно. Теперь надо сделать сервис максимально простым, удобным и надежным. И чтобы
эксплуатация также была простой. Наверное, хорошо бы сохранить способность сервиса к прямому подключению к приложениям,
видимо .Net Core приложениям. Посмотрю на текущий вариант, надо делать выводы. 

Никакого "посмотрю" не последовало. Последовала экскурсия к Карагемскому прорыву. Впечатляет!..

Вернусь снова к "посмотрю". 

### 20190730 07:38
Студия говорит, что исчерпался месячный испытательный срок и требует актуализации лицензии. Без интернета этого сделать я не могу, а она сволочь, отключает 19-ю студию. У меня есть еще 15-я и 17-я. Но они не подходят. Пробовал сменить дату на системных часах - получается. Но есть сомнения, что так будет лучше. Все же многие процессы осуществляются по времени. Тем не менее, если меня ситуация "достанет", то придется сделать именно это. Пока надеюсь работать без коррекции времени. Для этого, нужно отказаться от 19-й студии и пользоваться SDK и VisualStudio Code. А в сложных случаях, программный код можно вытаскивать в студию, там можно пользоваться редактором и системой подсказок. 

Посмотрю что работает, а что нет в режиме SDK.

### 20190731 08:49
Ночью был дождь, но мы в домике, нам это не страшно. С утра дождя нет, занимаемся завтраком. По ходу дела, я выявил неточность в определении загрузочного списка кассет, исправил, все работает как надо. Еще я обратил внимание на то, что Visual Studio Code уже очень не маленькая - в "боевом" состоянии от 660 Мб. до гигабайта "с хвостиком". Ну и ну, не пора ли переходить на продукцию JetBrains? 

С утра думал о формате данных, результатов и форматов. Тестовый вариант формата данных может быть естественным:
```
[идент, [поля], [прямые ссылки]]
```
А может быть и таким
```
[идент, [поля и прямые ссылки]]
```
Во втором случае, возможно расширение в сторону обратных ссылок, это дает формат результата. Но тогда должен существовать
спецификатор, напр. f, d, i. Будет что-то вроде:
```
[f, prop, "..."] // поле
[d, prop,  "..."] // прямая ссылка
[i, prop, "..."] // обратная ссылка
```
В семантике Поляра, представление 2 может выглядеть интереснее:
```
Record = {id: string, tp: string, arcs: [Arc]};
Arc =   
  field^{prop: string, value: string},
  text^{prop: string, value: string, lang: string},
  direct^{prop: string, recs: [Record]},
  inverse^{prop: string, recs: [Record]};
``` 
Допускается "обрывать" описание графа на любых списках. Типичным "обрывом" является прямая ссылка на узел. Например:
```
{"sypdb_p_mag", "http://fogid.net/o/person",
  [
    1^{"http://fogid.net/o/name", "Марчук Александр Гурьевич", "ru"},
    2^{"http://fogid.net/o/father", {"randb_marchuk_gi", null, []}}
  ] 
} 
``` 
В выборке, могут появиться и обратные ссылки или даже конгломераты. Есть альтернативы: можно где-то писать список, а где-то перечислять дуги по отдельности. Особенно, это важно при выдачи обратных отношений. Например,
```
{"sypdb_p_mag", "http://fogid.net/o/person",
  [
    3^{"http://www.w3.org/1999/02/22-rdf-syntax-ns#about", },
    2^{"http://fogid.net/o/name", "Марчук Александр Гурьевич", "ru"},
    4^{"http://fogid.net/o/reflected", [{"reflection12345", []}]},
    4^{"http://fogid.net/o/reflected", [{"reflection12346", []}]},
    4^{"http://fogid.net/o/reflected", [{"reflection12346", []}]}
  ] 
} 
или
{"sypdb_p_mag", "http://fogid.net/o/person",
  [
    2^{"http://fogid.net/o/name", "Марчук Александр Гурьевич", "ru"},
    4^{"http://fogid.net/o/reflected", 
      [
        {"reflection12345", []}
        {"reflection12346", []}
        {"reflection12347", []}
      ]}
  ] 
} 
``` 
Таким образом, формат тестового хранения данных может совпадать (быть подмножестовом) с форматом выдачи результатов. Выводятся или одиночные записи или потоки одиночных записей или последовательности одиночных записей. 

Теперь о форматах. Формат определяет выборку из графа RDF-данных. То есть, если формат применить к узлу графа RDF, будет 
собрано и выдано дерево запланированной структуры. Рассмотрим этот вопрос подробнее. Формат {null, []}, примененный к узлу "123" даст дерево {"123", []}, примененный к множеству узлов, выдать множество таких деревьев. Формат {"id", []}, примененный к множеству узлов, оставить в этом множестве только те, идентификатор которых совпадает с заданным. Таким образом, проставленный идентификатор, выполняет роль фильтра. Также фильтрами являются все полностью заполненные поля и прямые ссылки, имеющиеся в списке дуг. Все эти дуги в результирующее дерево не попадают. Это ограничение легко обойти, см. далее. 

Как работает фильтр? Имеется проверяемый узел, его исходящие дуги и имеется ограничение в виде дуги Arc. Сопоставление (Matching) дуг и ограничения (шаблона) дуги выполняяется по принципу: сравниваются соответствующие поля, если какие-то поля не совпадают, то сопоставление не получилось. Если в шаблоне указан null, то сопоставление получилось. Если все поля прошли такое сопоставление успешно, то формируется выходная дуга, совпадающая с дугой-образцом. Если по одному шаблону прошли сопоставление несколько дуг, все (? может нужен признак типа "первый" или "все"?) они помещаются в выходное дерево. Если не одна дуга не прошла сопоставления с шаблоном, то и все форматирование узла считается неудачным. Но может быть и "послабление", заключающееся в том, что в случае несопоставления, в дерево просто не помещается никакого результата. В Sparql это OPTION. С другой стороны, такая опция ранее мне не требовалась. И поля записи field отрабатывались в любом случае. Вот и подумаешь, нужен matching или не нужен. 

Пока можно сделать частный вариант сопоставления, сопоставление без фильтрации. А еще что делать с типом? Его указать полезно, но и в результате иметь тип достаточно интересно. В текущем варианте формата тип обработывается отдельно. Его можно указать или нет, он всегда выдается. Здесь даже можно фантазировать на тему дерева классов, наследования свойств и т.д. А еще есть существенный момент: альтернативы в формате. Это означает, что узел-цель может быть разных классов и по-разному формировать результирующее дерево. Кстати, это одна из причин сохранять тип записи всегда. Альтернативы сейчас "скрыты" в шаблонах прямых и обратных ссылок. 

В записи можно выделить отдельным полем тип этой записи. Эффективность многих процессов обработки возрастет. Остальные положения можно оставить прежними. Итак, простые форматы. Простые форматы работают на множестве узлов. В частном случае, это множество, состоящее из одного узла. Есть множество узлов и есть формат. Алгоритм работы формата:
1. Для каждого узла из множества, производим сравнение идентификатора и типа. Часть узлов могут отсеяться, для каждого из остальных, заводим деревья с вычисленными идентификатором и типом. 
2. Последовательно обрабатываем дуги шаблона. В простом формате, все предикаты определены. Для полей, (пока) допустим лишь шаблон {prop, null}, для текстов {prop, null, null} или {prop, null, "lang"}. Для полей, в результат попадает нуль или одна дуга для первого и третьего варианта, для второго - по числу корректных сопоставлений и шаблоном дуги. 
3. Для прямых ссылок форма шаблона следующая:
```
  direct^{prop: string, recs: [Record]},
```  
свойство (предикат) должно быть задано и может быть ноль или более типов цели. Если ноль целей, то годится любая и все исходящие из узла прямые ссылки войдут в результирующее дерево прямо списком:
```
  direct^{prop: "предикат", recs: [{id1, tp1, []}, {id2, tp2, []}, ...]},
```  
Если форматы записей указаны, то в результирующее дерево войдут только те прямые ссылки, которые пройдут сопоставление с шаблоном, при этом, произойдет раскрытие шаблона. С обратными ссылками - та же "история". Представляется, что существенным отличием прямых ссылок от обратных, является то, что у прямых ссылок может быть несколько шаблонов, а ссылка будет одна, а у обратных ссылок - один шаблон, а ссылок может быть много. Это следует из свойств применяемых онтологий, когда отношения не имеют подклассов и у них жестко зафиксирован набор объектных ссылок и эти ссылки не переиспользуются. 

Вроде конструкция достаточно интересная, наверное можно производить преобразования с текущими форматами, пора ли делать пробу?
Надо немного попробовать и оценить то, что получается. Допустим, пока мы оставляем текущую структуру базы данных. Соответственно, загрузка данных, соответственно набор выборок и изменений. С чего начать? Может с Unit-тестов. Хорошо бы, но студия не работает. А можно Unit-тесты делать в SDK? Наверное, сейчас посмотрю как генерируется юнит тест или что там генерируется.  

Еле-еле справился с созданием автономного решения. Последняя проблема - работа с кодировкой Windows-1251 иногда имеющейся в фог-файлах. С этим я (без интернета) не справился, пришлось убрать пару операторов. Но ничего, все заработало. Видимо в фогах нет других кодировока кроме utf-8. 

Итак, в проекте Dzhozator есть OADataService и попытка сделать юнит-тесты. Больше ничего.  

### 20190801 08:19
Вот уже и август наступил:(
В принципе, причины печалиться нет, но все же лето начинает уходить. Хотя сегодня, лето опять ожидается: с утра солнечно и температура быстро растет. Света говорит, что с утра было +3, сейчас на градуснике +15.

О чем я думал пока спал? В принципе, можно сделать структуризацию полностью Поляровской и даже хранить данные в бинарном виде. Страшно? Пожалуй, все же я предполагаю долговременное использование архивных сборок. Первым кассетам уже более 12 лет, их бы надо переработать, но пока годятся и так. И текстовый вид дает некоторые возможности... Потом я подумал о текстовом формате записи Поляровских структур. Он есть, вроде работает, но особенно нигде не используется. Можно проверить все ли там нормально и какие объемы информации допускает ввод и вывод. Еще подумалось о сканирующем чтении, возможно надо сделать Reader. 

А что делать сейчас? Надо довести сервис до кондиции. Во-первых, надо сменить абстракцию DBAdapter на более маленькую и содержательную. Кроме имеющихся XML-ориентированных методов, надо бы добавить Поляр-ориентированные. Те, которые я подразумевал разрабатывая новый стандарт под формат и результирующие деревья. Потом надо испытать новые методы сделав простой демонстрационный сайт. Еще можно разработать новый формат внедрения (Put) элемента в данные. 

Попробую. 

Что-то убрал, что-то оставил. Сходили в небольшой поход на 5.5 часов. Было тяжеловато, но сейчас вроде все прошло, набираем форму...

Пора начать разбираться с разными форматами фог-файлов. Все разные форматы должны быть только в режиме чтения. Тогда он читается, динамически преобразуется в текущий вариант и загружается в базу данных. Теоретически, можно этот текущий вариант записать заместо старого. Но это когда документ доступен для изменения. А если он берется из Интернета? Или как-то аналогично, тогда - никаких модификаций. В каких местах имеются варианты представлений, требующих изменений? Это - iisstore, delete, substitute, может еще что-то.

Самый неприятный оператор - substitute. В OWL это <owl:SameAs ...>. Противность заключается в том, что могут возникать цепочки эквивалентности, из-за распределенности, цепочни могут начать ветвиться, возможен разрыв цепочек. Причем нет очевидного способа устранения этих эквивалентностей. Действительно, мы можем физически переименовать сущности и ссылки в имеющихся фог-файлах. Но что делать с теми, которые не попали в сборку? Что делать с "внешними" относительно базы данных ссылками? Видимо придется сохранять эквивалентности. Возможно, надо включить фактор времени и использовать mT. Возможно, придумается какая-то "мягкая" чистка. 

Кто или что у нас генерирует фог-файлы? Это - кассетный менеджер и второе, наполнение базы данных. Кассетный менеджер очень устарел, но ему пока нет замены. Посмотрю на действующие трансформации содержимого фог-файлов. 

А еще я заменял идентификаторы. Это потому что их конструкция была неправильной,кажется там вертикальная черта была.

Такие дефекты как вертикальная черта, надо исправлять inline - трансформацией файла. Другие имеющиеся, надо также исправлять по ходу какого-то процесса обновления данных. 

Кстати, идея с привлечением mT для разрешения эквивалентностей, это интересная идея, надо будет подумать.

Возвращаюсь к трансформациям. Пока будут разные генераторы фогов, придется пропускать через трансформации. Можно "начать новую жизнь" с Поляровским хранением данных. Похоже, надо начать с генератора данных "фототека". Пусть сначала не будет кассет, а будет загрузка фога из файла. Это для работы - загрузка, а для тестирования - это файл, который надо сгенерировать. В конфигураторе добавим конструкции 
```
<GenerateFog param="значение">file path</GenerateFog>
<LoadFog>file path</LoadFog>
```

### 20190802 07:19
Пока я спал... Пришла в голову идея сделать потоковый ввод данных из строки или из потоковой строки. Все же мы говорим о больших данных! Можно его сделать через сканирование элементов последовательности. А что, читаешь квадратную скобку, сканируешь элементы до закрывающей квадратной скобки, сканированные элементы подвергаешь обработке хендлером. Посмотрю что у меня с текстовым вводом и выводом. 

Посмотрел. Почти все в порядке. Есть там замечание о формате числа с плавающей точкой, не отмечено замечание о подчерках в целых числах, нет полной формы (с ключами и текстовыми тегами) ввода и вывода. Зато есть потоковая форма текста и сканирование сделать легко. И потоковый вывод тоже. Пора пробовать.

Начал писать генератор для Фототеки. Совсем запутался в новых построениях, связанных с форматами и деревьями вывода. Вернусь к (модифицированному) старому построению для данных:
```
Record = {about: string, typ: string, arcs: [Arc]};
Arc =   
  field^{prop: string, value: string},
  text^{prop: string, value: string, lang: string},
  direct^{prop: string, resource: string};
```
Весьма компактная и эффективная форма. Можно потом "сложности" форматов и вывода "загнать" в варианты перечисления Arc. 

Сделал первые генераторы. Просто генерировать 1 млн. персон в объектном представлении получилось 1 сек. (В Core было 0.6 сек.) Запись в файл средствами UniversalSequenseBase производилась 5.5 сек. Размер файла 110 Мб. 

Итак, персоны отпрофилировал. 1 млн. штук: Генерация
```
  объекты 1.1 
  бинарный файл 4.1 сек 110 Мб
  XML 13.5 сек 109 Мб
```
### 20190803 08:10
Продолжу испытания
```
Для 1000 персон времена: 13 мс., 111 мс., 41 мс.
Для 10000 персон времена: 35 мс., 62 мс., 98 мс.
Для 100000 персон времена: 132 мс., 383 мс., 1403 мс.
Для 1 млн персон времена: 1025 мс., 3633 мс., 13353 мс.
Для 10 млн персон времена: 10.5 с., 37 с., 181 с. (3228 Мб ОЗУ)
```
Продолжу разработки. Сейчас проведу эксперименты по использованию XElement
Сделал (наконец!) ввод через XElement. Теперь пространства имен остаются в корневом элементе. Проведу новые расчеты. Последняя цифра будет для XElement
```
1000: 15, 24, 34, 20
10000: 36, 67, 97, 68
100000: 109, 388, 1415, 987
1 млн.: 1 с., 3.5 с., 13.4 с., 9.2 с.
10 млн.: 10 с., 36 с., - , 106 сек. (2400 Мб ОЗУ)
```
В последнем случае, третий вариант не считал, чтобы лучше засечь потребляемую память. 

Можно теперь еще испытать все это в .NET Core. Попробую.
```
10000: 20, 80, 128, 128
100000: 70, 361, 1412, 1125
1 млн.: 538, 3.3 с., 12.5 с., 9.2 с.
10 млн.: 5 с., 30 с., - , 116 сек. (4300 Мб ОЗУ)
```
Прогнал, теперь можно возвращаться к разработке. Следующий этап - ввод данных. Сначала испытаю ввод в простом режиме, просто загрузка или сканирование данных.

Сканировние бинарного файла (1 млн. персон) выполнялось 4.8 сек. - чуть дольше, чем ввод данных.
Загрузка xml-файла в XElement (1 млн. персон) выполнялась 5.6 сек. - все весьма сопоставимо. Только затраты ОЗУ были 253 Мб. 

Все понятно, все объяснимо. XML-ридером пока заниматься не буду. Надо сформировать следующий шаг.

Следующий шаг выдача базы данных в текстовом виде и сканирование ее из текстового вида. Придется сделать некоторые доработки в Polar.DB

Сделал. Формирование поляровского текстового файла получилось. Только без форматирования данные понимать сложно. Как делать форматирование? Видимо нужен параметр глубины. Отдельные сериализации будут начинаться с этой глубины. У записи и последовательности, открывающие и закрывающие скобки находятся на заданной глубине, элементы - на уровень выше. Разделители (запятые), должны замыкать запись элементов. Объединение надо сделать так, чтобы тег был на уровне, а элемент на следующем уровне. Надежно это можно сделать лишь если развести их по строчкам. Как-то так... Надо попробовать. Чтобы не "курочить" имеющуюся процедуру, изменения сделаю в ее копии.

Сделал форматированный вывод (сериализацию). Как-то некрасиво получилось. И я не уверен, что практично. 17 строчек на одну запись вместо 4-х в формате XML. 

Внес ряд изменений в форматированный вывод. В частности, определил простой тип как или атомарный или строку или запись птомарных или строк. Атомартые типы я не форматирую и они выводятся в строчку. Также в строчку выводится объединение, вариант подтима которого атомарный. Теперь запись базы данных стала 8 строчек. Это всего лишь в 2 раза больше, чем в формате XML. Теперь надо проверить ввод (сканирование).

Вроде получилось. Загрузка и запись в текстовом формате и сканирование (вторая колонка) дают результаты
10000: 57, 73
100000: 656, 761
1 млн.: 5,6 s, 6.6 s
10 млн.: 54 s, 64 s

Результаты вполне обнадеживающие. Теперь можно двигаться дальше. Сначала я доделаю Фототеку. Потом начну загружать данные в сервис. Надо понять как будет вести себя сервис. Потом надо будет сделать редактирование через сервис. Как-то так...

Сделал генерацию комплексного теста, теперь у мя есть комплекный тест на 10 тыс. персон в трех форматах. Пока я умею загружать только XML-RDF. Надо сменить корень и будет все нормально. 

Сделал генерацию одиночных фог-документов, потом исправил одну ошибку, теперь сервис работает на базе данных, сгенерированных тестом Фототека. Пожалуй, можно попробовать сформировать данные большего размера.

### 20190804 06:51
Сегодня у нас план сняться с базы на Джозаторе (база Кожака) и продолжить наш отпуск на Алтае. Вариантов два: либо сразу ехать в Чендек и идти в поход на Аржан, либо сначала заехать на Семинский перевал, определиться с погодой, зафиксировать наработки в гитхабе, созвониться, поинтернетить, а уже потом ехать в Чендек. Если надо вернуться 12 августа, то хорошо бы выезжать с Алтая 11-го и иметь день на адаптацию в Новосибирске. Четыре дня (с запасом) нам надо на поход к Аржану. Это значит 7-10 августа, а сегодня - 4-е. Люфт очень маленький, но и в дождь идти в поход не хочется. Последняя наша попытка дойти до Аржана оказалась бесуспешной именно из-за дождя... Так что важно добраться до прогноза и выяснить перспективы. 

И еще надо собрать наработанное. В силу дурацкого отказа в пользовании студией 2019, ряд разработок переместился со своих мест в другие. Конкретно это касается следующих частей:
- Проекта Polar.DB - он сейчас развернут и уже модифицирован под .NET Framework в решении PolatDBsbor, надо вернуть его в решение PolarDB.
- В этом же решении, в проекте TestDataGenerator производятся эксперименты по форматированию базы данных и генерации теста Фототека для использовании в сервисе.
- Проект OADataService временно перемещен под директорию (решение) Dzhozator, там я его дорабатываю и запускаю через API и командную строку. 
- Есть еще проекты Turgunda3 и OpenArchive5, вместе с техническими проектами CassetteKernel, PolarBaseEngine, PolarDB (старый вариант), sema2012m. Они работают на сервере gea.iis.nsk.su и в Тургунде уже произведена частичная адаптация к сервису данных. Но не испытана и не протестирована. Кажется, надо пересобрать весь этот конгломерат под единым решением, пусть он и будет адаптирован к старому .NET.
- А еще есть ЛШЮП, сейчас софт для нее "загнан в подпол" - последний работавший вариант это C:\home\devbefore2017\Turgunda6\Turgunda6. Кажется... И вполне прилично работал по редактированию ЛШЮП'овских данных

### 20190805 07:46
Вчера долго, долго ехали и приехали на Семинский перевал. Сюда, потому что, когда выехали в зону мобильной связи, "прилетели" смс-ки и почта, выяснилось, что Коля просит приехать в Москву 10-го. Пришлось срочно корректировать планы. Здесь, на Семинском, по Интернету (отличная штука!) купил билет и теперь у нас есть 3 дня, которые можно еще провести на Алтае... Вчера весь день была жара - в разных местах по-разному, но в долине Ини +34 градуса, на Семинском +20. А вечером здесь пошел дождь, ночью периодически шел дождь, утром идет дождь, в прогнозе на сегодя - дожди...

Итак, надо поработать. Вчера я набросал практически план. Ночью я получил новые Credentials по вопросу пользования Visual Studio 2019, так что можно работать над выполнением плана. 

Пункт 1. Возвращаю Polar.DB на место. Я там делал модификации: в одном файле неявные записи (a, b) заменил на более традиционные Tuple(a, b). В другом месте, изменения были содержательными. В частности, были добавлены: запись потока в последовательность и форматный вывод. Пока не сделал ввод/вывод идентификаторов полей и вариантов. Сделал.

Пункт 2. Переместить обратно проект сервиса OADataService в PolarArchiving. Вроде сделал, надо испытать. Испытал, работает. Некоторые сомнения есть по поводу инициирования работы. Сейчас построение базы данных происходит при каждом запуске сервиса, а вот директория базы данных не чистится. Еще одно сомнение заключается в том, что внешние библиотеки типа Polar.DB для эффективности нужно компилировать с опцией Release, а для отладки - с опцией Debug. 

Пункт 3. Надо поместить генерацию тестовых данных в решение PolarArchiving. Поместил, опробовал - работает. 

У меня возникли сомнения о другом - где в хранимом документе, напр. фог-формата записывать нужную системе метаниформацию. Метаинформация следующая: Имя кассеты, свободный (новый) uri, владелец документа, параметры генерации новых идентификаторов. В XML я уже привык хранить метаинформацию в атрибутах XML-документа. Это не слишком идейно для RDF, но возможно. Поляровский формат снова ставит эти вопросы. Можно хранить эту информацию "снаружи", можно сделать маленькую базу данных для хранения метаинформации. Можно в конструкции кассеты что-то выдумать. Можно, как и для XML, усложнить конструкцию поляровского объекта. Последнее - нежелательно. 

Интересным решением является то, что в маленьком хранилище может быть один (?) элемент, хранящий метаинформацию. Если это хранимая неизменяемая информация, то вроде все в порядке: прочитал один раз и храни эту информацию в своих динамических таблицах. А если надо изменять? Как каунтер, например? Для небольших хранилищь, все это не страшно - изменения производятся в динамичеком объекте и периодически "сбрасываются" в файл. В таком, как XElement.

Кстати, о Поляровском динамическом объекте. Понятно, что это десериализация. Но у меня пока нет методов работы с этим объектом. А было бы полезно иметь такой набор. Немного пофантазирую. Пусть есть поляровский объект, есть его тип и мы
начинаем методы: 
Если тип атомарный, мы легко (приведением) получаем соответствующее значение. Если тип является записью, то метод Field(i) 

PolarObject является парой object (Polar Value) и PType. 
```
PType PType(PolarObject this);
object Value(PolarObject this);
PolarObject Field(PolarObject this, int index);
PolarObject Element(PolarObject this, int index);
PolarObject Sub(PolarObject this, int index);
```
Value - ссылка на объект, эту ссылку можно изменять. Как это делать? Может и нельзя? Пусть есть объект seq в виде последовательности объектов строк. Тип такого объекта очевиден [sstring]. Понятно, что выборка seq[i] даст объект-строку. И вроде если seq[i] = "another", то получится то, что мы имеем ввиду. Мы не в C, поэтому иметь в виде ссылки seq[i] (наверное) не получится. Но иметь ссылку на seq вполне можно. 

Я посмотрел на PaEntry, в принципе, что-то похожее есть, но и отличий много. Главное отличие в том, что там есть указалеть на начальный байт, это позволяет и читать и, в некоторых случаях писать и передвигаться. Здесь есть ссылка на объект, читать и передвигаться мы можем, а вот запись может быть только к полям объекта. Соответственно, методы могут быть SetField(int nom, object val), SetElement(int ind, object val), SetSubelement(object val). Зато никаких ограничений, только корректность по типам, которую я пока не проверяю. Хотя почему бы не проверить? 

Вообще, средство интересное, но что это может дать для хранения метаинформации? 

Еще одна "сторонняя" идея заключается в том, чтобы на подобных принципах сделать Reader. Пока не буду думать об этом. 

Вернусь к хранению метаинформации. У нас есть записи вполне определенной структуры: идентификатор, тип, поля и ссылки. Что может выделить эту запись? Конечно тип! Хотя не стоит исключать и идентификатор. Пусть идентификатор будет идентификатором документа. Зачем он нужен - не знаю, но может понадобиться. 
```
{id: string, tp: "metainformation", arcs: 
  [
    f^{"owner", "идентификатор пользователя"}, 
    f^{"prefix", "префикс к конструируемым идентификаторам"}, 
    f^{"counter", "1001"} // значение каунтера 
  ]
}
```
Как-то так... Документ будет доступен в виде объекта, если появляется новая запись, ее идентификатор проверяется на наличие в документе, потом или заменяется или добавляется. Для добавления в набор записей был бы полезен список List<>. Кстати, список вполне мог бы сочетаться с массивом. Обычно я не проверяю на то, что объект есть массив, но можно и проверить. Потом как-нибудь. А может и не потом... 

### 20190806 
Проанализирую объект CassettesConfiguration, который является ключевым в сервисе.
1. Объект содержит статический метод определения расположения кассетной директории по uri. Метод сомнительный, надо это место уточнять.
2. В кассете есть два списка (массива) того, что нужно для корректной работы и абстрактный адаптер (базы) данных: 
```
        private static CassInfo[] cassettes;
        private static FogInfo[] fogs;
        private static DAdapter adapter = null;
```
Посмотрим на структуру элемента списка кассеты: информация о кассете содержит имя кассеты, path корня, имя владельца и признак writable. 
3. Единицами хранения данных, являются так называемые "фоги", документы, которые попали в список fogs. Документы заданы своей координатой файла, имеют владельца и признак writable. Кроме того, есть ссылка на объект, которая либо null, либо хранит объект, являющийся динамически образом документа. Если документ изменяется, то изменяется его динамический образ исохранение образа сохраняет изменения в файле. У фога может не быть владельца или признака writable, тогда документ считается неизменяемым.
4. Конфигуратор (коллектор, ассемблятор, сборщик?) инициирует статическое наполнение через обычный конструкутор объекта. Видимо надо запретить конструирование другого объекта, интересно, а как это сделать?
5. Конфигуратор конструируется XML-объектом xconfig в котором он берет список загружаемых кассет и формирует список фогов. Фоги берутся из конкретно указанных файлов (не уверен, что это обязательно) и фогов, извлекаемых из кассет, поскольку кассеты хранят документы, а фоги - это документы. 
6. Потом есть набор статических процедур доступа к данным. 
```
        public static IEnumerable<XElement> SearchByName(string ss)
        public static XElement GetItemByIdBasic(string id, bool addinverse)
        public static XElement GetItemById(string id, XElement format)
        public static XElement PutItem(XElement item)
```
Эти процедуры XML-ориентированы, поддерживают разные варианты айтема, а процедура GetItemById еще и опирается на непростую семантику использования формата, представляемого в XML. Можно расширить этот набор с соответствующим расширением реализаций в адаптерах. Или можно заменить его на другой, а это сделать через другой. 
7. Пока отсутствуют диагностика неприятностей и способы анализа и восстановления данных.  

В общем, работать и работать... Но делать сервис данных надо, иначе я не смогу подключать к работе других, напр. Трошкова, а мне одному уже не справиться. 

План работы над сервисом такой. Сначала я делаю адаптер структурный построений, который я согласовал. Я там довожу все до XML, может пока XML-форматы не трогаю. Потом пытаюсь встроить новый адаптер в сервис. Потом вывожу из сервиса новый набор методов и пытаюсь их использовать. По-крайней мере - через XML. Но сначала, сохраню наработанное в гитхабе. Сохранил, хотя и не без проблем.

Начинаю с фог-документа. Буду различать через расширение разные структуры фогов. Для XML будем использовать .fogx, для Поляра будем использовать .fogp, для (в будущем) JSON будем использовать .fogj. Просто .fog будет старый формат в XML. 

Изготавливаю простой fogp документ. Простой, это значит без метаинформации. Изготовил, вставил его в конфигуратор config.xml. Теперь начну обрабатывать. 

Надо сделать fogs_list, а потом и array. У FogInfo добавляем признак vid. Признак добавил, но пока не использовал. Проверил работоспособность на fogx и на кассете (с фогами). Теперь приступлю к встраиванию поляра в обработку. 

В переделке кода дошел до загрузки фогов. Это дело тонкое, надо выполнить его аккуратнее. 

Более или менее вспомнил как это устроено и выяснил что надо делать. Только слияние идентификаторов представляет проблему. Можно пока эту проблему не решать, тем более, что в данных ОА удалось ее избежать. А по-существу, загрузка осуществляется из потока фогов. Каждый фог распадается на множество записей. Каждая из записей имеет свой тип и свой идентификатор. Некоторые из записей несут техническую роль, например метаинформационные записи. Можно "обернуть" кассету объектом и в нем накапливать нужную в других местах информацию.

Итак, что я могу сказать про объектную "обертку" для фог-документов. Наверное то, что это будет абстрактный класс или интерфейс. Вложил документ и получаешь всякую информацию и нужные потоки. В принципе, этот же мезанизм можно использовать для миграции данных из одних (старых) форм представления в другие (новые).

Попробую набросать такой абстрактный класс
```
public abstract class SmallSource
{
  public FogInfo Info { get; set; }
  public IEnumerable<Tuple<string, string, DateTime>> Scan1();
  public IEnumerable<object> Scan2();
  public object Put(object);
}
```
Суть этого класса в следующем. Первично, наверное в конструкторе, фиксируется путь к файлу и вид фога. Возможно устанавиваются также некоторые значения, напр. writable, owner. Далее, работает первая сканирующая процедура. Ее задача просканировать файл, изъять из него метаинформацию и зафиксировать в поле Info, а также организовать поток записей из которых в выходной поток берется идентификатор записи, возможно, эквивалентный идентификатор, заданный отношением 
```
<owl:SameAs rdf:resource="более главный идентификатор"/> 
```
и метка времени, задаваемая отношением 
```
<mT>время фиксации записи (универсальное)</mT>
```
Результат сканирования используется специальным образом так, что в итоге, вычисляются: для одинаковых идентификаторов максимальная отметка времени и, второе, конец дерева эквивалентностей. Т.е. для каждого идентификатора, попавшего в цепочку эквивалентностей, тот идентификатор, который признан оригиналом. 

### 20190807 15:44
С утра работаю над загрузкой фогов. Решил сначала сделать "старые" XML-фоги. Выяснились неожиданности в реализации - как-то преодолел. Выяснился тонкий момент, на который я раньше похоже не обращал внимания. Если запись с идентификатором id уничтожена, то и в поток записей в базу данных ничего с id не попадает. А тогда как интерпретировать приход Put(rec) с тем же идентификатором? Похоже, в динамической базе данных, появится элемент с уже выброшенным идентификатором. Но после перезагрузки он "исчезнет", поскольку delete блокирует всю цепочку и, если нет отметки времени, то и более поздние элементы цепочки. Об этом надо подумать! Правда откуда появится уже уничтоженный идентификатор? Непонятно...

### 20190810 10:16
Время уже московское. Я приехал, устроися и не тороплюсь звонить Коле со Светой. Пока решил немного проработать. В самолете мне показалось, что вполне уместно делать TestUnit'ы для проверки работоспособности решений. Сейчас мне так не кажется, тем более, что доступ к документации затруднен. 

Продолжу делать традиционный испытательный стенд TestCC. Сейчас написан и работает фрагмент, создающий базу данных на основе одной существующей кассеты. А потом запускается внутренний тест Test() на этой базе данных. Все похоже на правду. Намечу план тестирования и совершенствования источника данных OAData. Чтобы делать несоклько испытаний в одной программе, нужна очистка источника данных. Если бы OAData был простым объектом, то его "обнуление" и конструирование заново решало бы проблему. Может его и сделать простым объектом и не связываться со статическими переменными и методами? Сейчас статичность подчеркивает то, что мы не можем (не имеем теории) управлять несколькими базами данных на основе нескольких кассет и фог-файлов. Попробую все же сделать динамичный метод Clear(), но который будет вычищать статичное решение. 

На самом деле, пришлось поработать не над Clear, а над Close(), что по смыслу означает открепление или отключение от файла. Файлов много (10 штук), вот от них и надо отключаться. Вроде справился, теперь фрагмент 
```
      OAData.OAData cc = new OAData.OAData(xconfig);
      cc.Test();
      cc.Close();

      OAData.OAData cc1 = new OAData.OAData(xconfig);
      cc1.Test();
      cc1.Close();
```
не "ругается" на то, что какой-то файл занят, а исполняется корректно. Теперь пора заняться отдельным fog-документом. Предположим, отдельные фог-документы также возможны в наших конфигурациях (сейчас уже ест конструкция LoadFog). Если у Фога есть необходимые отрибуты (владелец, префикс и каунтер), а также есть разрешение туда записывать, то можно использовать этот фог в "мирных целях". Попробую. 

20190811 11:34
Сегодня уже "поразвлекался" судебными делами... Пока не вызвали, можно что-то попытаться сделать. 
А вчера и с утра сегодня опять "мучился" с пространствами имен и префиксами в XML-документах. Вроде 

20190812 12:15
Я думал будет больше времени для личной работы. А так, уже два дня подряд, я возвращался домой очень поздно. Скоро придут Света с Колей и опять не будет возможностей. 

Тем не менее, чуть-чуть я продвинулся. Я добился того, что заработал оператор delete. Какие особенности связаны с этим оператором. Главная особенность в том, что я сделал идентификатор по RDF-схеме, т.е. rdf:about. Но есть и проблемы. Оператор "вылезает" при выдаче всех GetAll(). А не должен бы. Потом, не знаю какое решение принять в проблеме повторного определения идентификатора. Для начала, уберу выдачу оператора. Надо это сделать на каком-то уровне. Видимо - на максимально глубоком. 

### 20190813 05:35
Вчера так и не разобрался с уничтожением айтемов. Не сказать, что задача трудная, просто пришли Коля со Светой и мы до поздна работали над семейными делами. 

А проблема кажется не сложная. Вспомню уже описанную логику работы key-value хранилища. Там был признак isnull, определяемый конкретно в каждом случае. Понятно, что в нашем конкретном случает с хранилищем триплетных записей, это может быть кодированный эквивалент оператора
<delete rdf:about="идентификатор"/>
оператор естественно преобразуется в тройку и если его снабдить временной отметкой - то в две тройки (запись):
```
<идентификатор> a <http://fogid.net/o/delete> .
<идентификатор> <mT> "отметка времени" .
```

Вопросом является то, допускаем ли мы процедурную форму уничтожения или нет. Процедурная фотрма или что-то вроде remove(id) ничему не противоречит если ее преобразовывать в запись с отметкой времени. Отметка времени означает то, что значение null для ключа <идентификатор> будет доминировать до указанного времени, потом идентификатор можно начать снова использовать. Тут появляется эффект "фантома", когда например зафиксирован delete до будущего времени t1 и "нормальная" запись с искусствнно заданым временем t2 > t1, тогда по наступлению t2 "вдруг" возникнет эта когда-то сделанная запись под данным иднетификатором. Хорошо это или плохо - трудно сказать, надо ли доопределять семантику чтобы блокировать такие возможности - также непонятно. Пока я не собирась это свойство использовать, а отметка времени формируется автоматически. Сетевые эффекты, связанные с отметками времени, я пока не анализировал. 

Общий вывод такой - надо четче зафиксировать оператор уничтожнения в базовой онтологии. Вообще-то вариантов, как минимум, два. Тот, который я указал и другой, когда мы к "нормальной" записи добавляем свойство типа isnull, указанный пример преобразуется во что-то, что будет зависеть от уничтожаемого значения. Например,
```
<идентификатор> a <http://fogid.net/o/person> .
<идентификатор> <isnull> <null> .
<идентификатор> <mT> "отметка времени" .
другие свойства и поля старого значения записи
```

Технически, с таким уничтожением работать труднее, поэтому лишь отметим этот вариант и двинемся дальше. Есть одно маленькое потенциальное преимущество варианта: если неиспользованное значение <null> заменить на что-нибудь вроде <true> и <false>, то можно будет изменять статус записи простым переписыванием поля. Но является ли это преимуществом - не знаю, появляется какая-то более изощренная семантика и скорее всего усложняется логика работы с данными. Останавливаюсь на управлением через тип. Кстати, при управлении через тип, существует похожая возможность переписываением кода типа менять статус записи. Брр..., не хочу двигаться в эти тонкости. 

Видимо надо зафиксировать код для <http://fogid.net/o/delete> и далее что? Далее, появление записи с таким кодом типа, должно приовдить к тому, что: 1) запись фиксируется к каком-то фоге, 2) в базе данных уничтожаются все записи и заданным идентификатором, но новая запись не записывается. Как-то так!..

Все реализовал, теперь работает. Трудно слишком детально оттестировать эту группу решений, но я попробовал все основные. Тем более, в части редактирования, все сведено к PutItem();

Тестировать мне в консольной программе мне уже расходилось, пора переходить к сервису и посмотреть работу хранилища и адапатра там. Бросаю проект TestCC, возвращаюсь в проект OADataService. Только надо сделать небольшое переименование. Класс, которому есть статические методы по доступу к данным, сейчас называется DB. Это уже лучше, чем CassettesConfiguration, но теперь уже слишком обще и может налогаться на какие-то внешние идентификаторы. Переименую этот класс в OADB. 

Переименовал. Активирую сервис. 

### 20190818 10:00
Кажется, сервис заработал. Надо его довести, но это не так просто. Попробую вернуться к старым проектам. Именно они требуют нового решения. 




