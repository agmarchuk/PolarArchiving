# Заметки по проекту TurgundaCommon

В принципе, эта библиотека предоставляет общие средства для работы с объектами Тургунды. Можно сказать, что это  интерфейс хранилища данных data storage. Что в интерфейсе есть? 

ONames.cs: онтологические имена. 
ModelCommon.cs: Онтологические имена и прилегающая информация. Можно сказать, онтологическая "кухня" - словари, переводы слов, загрузка онтологий  

SObjects.cs: Статические объекты хранилища. Работа с accounts, вспомогательные переменные и настройки. Главное - один движок engine класса CassetteIntegration.  В нем - "самый главный" статический метод редактирующей работы с хранилищем 
```
    public static XElement PutItemToDb(XElement item, bool tocreateid, string username);
```
База данных содержит множество идентифицированных айтемов. 
Метод предполагает, что в хранилище помещаются айтемы. Айтем идентифицируется атрибутом rdf:about, если он есть. Это два варианта: есть: а) и нет: б). 
Вариант б) предполагает, что генерируется новый идентификатор, добавляется к указанному айтему, айтем помещается в базу данных, а процедура возвращает сгенерированный идентификатор. Вариант а) предполагает добавление айтема к базе данных, если айтем с этим идентификтором уже существовал, то предполагается вариант редактирования, когда новый айтем или "убивает" старое значение, либо "маскирует" его. Если имя айтема "{http://fogid.net/o/}delete", то айтем с указанным идентификатором уничтожается или маскируется. Это не должно препятствовать дальнейшему появляению айтема через следующие операторы. 

На самом деле, есть еще имя пользователя username. Что оно означает и как оно используется? Оно означает текущую идентификацию пользователя, посылающего оператор редактирования. Все множество айтемов распадается на подмножества (fog-докумненты). Причем каждое подмножество имеет единое имя владельца (пользователя) и единый режим редактирующего доступа владельца к fog-документу. Редактирующее изменение, запрошенное оператором PutItemToDB произойдет, если  существует хотя бы один fog-документ, в котором владелец тот же, что и username и полномочия на изменение документа имеются. В этом случае, изменнение будет внесено в соотвествующий fog-документ в виде нового айтема или редактирования имеющегося айтема с данным идентификатором. Для того, чтобы в дальнейшем выявлять более поздний айтем, каждый айтем снабжается временной отметкой. Уничтожение айтема всегда (!) должно происходить как редактирование с сохранением последней временной отметки. 

Есть еще механизм замен. Может появиться оператор substitute с атрибутами old-id и new-id, "сливающий" два множества айтемов с разными идентификаторами в одно с назначением в качестве общего идентификатора new-id. В этом массовом действии есть скрытые семантические проблемы. Например, если есть объединительная запись, но потом она не попала в базу данных, то айтемы могут снова "распасться" и уже уничтоженные айтемы могут снова появиться. Правда это возможно и для отстутствия оператора substitute. Есть и другая проблема оператора. Она заключается в том, что идентификаторы, напр. old-id накапливаются не только в базе данных, но и во "внешнем мире" и там их трудно переделать. Это ограничивает возможности прямого переименования old-id -> new-id. 

Технически, подстановка может осуществляться таблицей id -> id, указывающей подмену. При наличии большого количества идентификаторов, эта таблица может оказаться довольно громозкой. Однако, если исходить из предположения, что таких подстановок малое, относительно общего, число, такую таблицу можно построить только для переименованных идентификаторов. Все остальные построения и действия могут быть сохранены как для предыдущего случая.  Можно также не допускать динамического переименования (подстановки), тогда таблица будет формироваться только при загрузке базы данных. Или ее дозагрузки. 

Еще существенным моментом является синхронизация. Вполне возможным является использование критического интервала через одну синхронизационную переменную. Причем и на редактирование и на неизменяющее чтение. 

### 20181113 11:31
Я вчера не смог придумать схему более экономную в синхронизации, чем общий критический интервал. Все кажется, что при доминировании доступа по чтению, можно было бы использовать этот факт. Пусть есть булевcкая переменная типа read_access_awailable. Если эта переменная истина, то можно без ограничений выполнять операции доступа, имея ввиду, что запись или модификация данных не ведется. Если требуется начать запись/модификацию, то можно эту булевскую переменную установить в ложь. И тогда можно было бы начать синхронизацию операций записи/модификации, так же как и чтения/неизменяющего доступа, через критический интервал. Проблема заключается в том, что у нас нет механизма выяснения того, когда предыдущий поток операций неизменяющего доступа закончится, чтобы уже начать синхронизацию. Возможно будет полезно, в этой задаче использовать семафоры. Обнуление семафора и будет таким сигналом о переходе в режим записи. 

Вернусь к модели слияния (факторизации?) имен. Сначала попробую разобраться с ситуацией без фаторизации. Есть айтемы, у которых есть идентификаторы и есть временные отметки. Возьмем "классическую" последовательность айтемов. Построим простейший индекс и будем выбирать по ключу все айтемы, а потом находить с максимальной временной отметкой. Будет такая конструкция работать? Будет! Более того, если разбить множества айтемов на подмножества, то также будет! Только появится еще один поиск максимальной временной отметки теперь уже по подмножествам. 

Теретически, временную отметку можно было бы заменить на порядок в последовательности, поскольку ее рост выполняется в "хвост". Однако, это ограничит использование подмножеств. В принципе, подключение кассет может быть динамическим в том смысле, что в кассете может быть своя развернутая база данных. По крайней мере, прямая задача key-value так решается. Но есть и обратная задача: по заданному идентификатору, найте все записи, в которых он присутствует в позиции ссылки. Эта задача также распадается на подзадачи для подмножеств айтемов и общее решение - объединение частных решений. Однако, как же технически решать ее для случая наличия временных меток. Можно никак не решать. Можно через векторый индекс. Можно через идентификаторы айтемов и их объединение. Так пожалуй - идейнее...

### 20181115 11:42
Попробую оценить насколько вопрос слияния (факторизации) имен актуальный в контексте Открытого архива. Для этого, надо промерить загрузку всех данных в OA на сервере.

Посмотрел на реализацию ri_table, ответственную за слияние. Выглядит тяжеловесно... Возможно, было бы правильнее использовать хеш-функцию и битовую шкалу. Например, проверяем какой-то идентификатор, получаем целое через хеш-функцию, отмечаем позицию в битовой шкале. Если позиция "занята" предыдущей отметкой, то выделяем это значение список. При повторном сканировании для всех идентификаторов, попавших в список, строим какое-то интересное построение. 

Проверил. Действительно, в базе данных открытого архива есть более 14 тыс. уничтожений, но нет подстановок. Поскольку пользователи не просят, видимо и нет актуальности этого механизма. Операторы delete можно заменить на что-нибудь более естественное. Например, на полностью пустую запись, т.е. есть только rdf:about и отметка времени. 

Одна из мыслей, которая меня беспокоит, это куда девать информацию об создателе записи owner. Можно заграть эту информацию в поле записи. Можно записи разбить по создателям. Технически, на кассетном уровне, делается именно это. Еще одна мысль - как бы уменьшить необходимость делать запрос ко всем fog-документам? Предпосылка такой возможности в том, что основа локальной базы данных идентифицируется "своими" идентификаторами. Но есть и "чужие". Можно было бы выделить все эти "чужие" идентификаторы в единую часть, например, одну на кассету и набор тестируемых документов бы резко сократился. 

Попробую сделать некоторое "классическое" решение несмотря на возможные неэффективности. Итак,пусть база данных будет содержать классические "тройки"...

Еще раз подумал и решил, что пока не дозрел до такого решения. Попробую модифицировать решение, основанное на XML-элементах. 

Начал работать. Выявил, что в базе данных Открытого архива сейчас около 407 тыс. элементов. База данных просто грузится по XElement.Load() порядка 3 сек.

Теперь надо формировать базу данных. Причем попробую это сделать не в оперативной памяти. Примитивное решение - просто XML-элемент в текстовом виде. Можно попробовать. 

Попробовал. Запись последовательности всех 407 тыс. Элементов выполняется за приблизительно 8 сек. Это быстро. Теперь надо сделать индексное построение на ключ элемента. 

### 20181116 11:18
Что меня беспокоит? Надежная работа RDF-движка! А еще хочется, чтобы он работал быстро и чтобы холодный старт осуществлялся также быстро. Наверное, проще всего снова сделать движок на базе XML. Только надо бы сделать по-другому уничтожение и замены. Насчет уничтожения - буду двигаться в сторону "стандартного" решения, когда запись заменяется "нулевой". Насчет замен - в Открытом архиве их нет, пока может не заморачиваться. Насчет динамики - можно все сделать на fog-документах. Добавление нового или редактирование старого будет формированием этого элемента, поиском фог-базы для помещения, добавление или замена имеющегося, сохранение в файле. При этом, должны выполняться коррекции таблиц. 

### 20181120 11:51
Кажется, самым протым движком может быть следующий: 
1) В оперативной памяти разворачивается весь набор fog-документов. 
2) Создается специальная индексная структура в виде словаря, входом которого является идентификатор сущности, значением некоторая запись, включающая в себя fog-запись оригинала и список обратных ссылок. Обратной ссылкой у нас будет элемент с атрибутом rdf:resource, "ведущий" к айтему с текущим идентификатором сущности. 
3) При редактировании айтема, появляется его другое значение. Также оно снабжено отметкой времени и владельцем. По имени владельца, находим текущий активный пользовательский документ. В этом документе находим запись с заданным идентификатором. Если запись есть, то заменяем (!) ее, если нет, то добавляем элемент. "Пустой" элемент изображается элементом с локальным именем delete. 

### 20181209 11:00
Схема неплоха тем, что почти не порождается дополнительных структур в оперативной памяти. Однако, базу данных надо иметь в виде множества XML-объектов и в оперативной памяти. Кроме того, начальная фаза может быть заторможена из-за загрузки и построения дополнительных структур. 

Какая может быть альтернатива? Вариантов несколько. Можно объекты представлять записями, можно триплетами, причем с вариантами: однородно или разделяя объектные и атрибутные. Можно кодировать или не кодировать. Кодировать можно биективным отображением или хеш-функцией. Все это может стать предметом исследования и статьи. А сейчас мне нужно решение. 

Возможно и смешанное решение, когда редактируемые fog-документы делаются по схеме XML, а нередактируемые - по другой. Кстати, можно будет примениять и в индексах неизменяемые решения. 

Начну с простого решения SimpleDBAdapter. 

Начал, но пока мало продвинулся. Я вот еще подумал, что двигаться надо к максимально автономному решению. Это когда есть одна (!) кассета и можно ее посмотреть, можно с ней поработать. Это будет понятно пользователю. Есть у меня такая... Называется SypCassete. Там могут быть некоторые "бяки", но попробовать можно. 

Загрузил, в ней 6671 элемент. Буду пробовать. Сначала на посмотреть на присутствие уничтожений и подмен. Их нет. Но есть другие заморочки. Есть iisstore и нет базового пространства имен для элементов. Вообще-то такие fog-файлы надо будет потом перекодировать. А может - и не потом, а сразу. Надо будет приводить все к единому стандарту. А потом, когда-нибудь, еще и перевести в онтологию в BONE. Не знаю, может ли в этих преобразованиях единый подход, но пока это другая тема. Сейчас буду пробовать. 

Нашел ошибку в данных. В упомянутой кассете SypCassete, сформированной Лештаевым, не совпадает dbid и идентификатор кассеты. 
```
  <cassette rdf:about="Cass_mag02_cassetteId">
    <name>Cass_mag02</name>
    <cassetteUri>iiss://Cass_mag02@iis.nsk.su/meta</cassetteUri>
  </cassette>
```
А это оказалось в некоторой ситуации - плохо. Возможно, надо перейти к унияицированному решению, напр. использовать только идентификатор объекта кассеты, но ведь он искажен намеренно... Причем и там и там... Еще можно проверять и предупреждать. 

Еще вылезла одна неисправленная "бяка" - в кассете почему-то не визуализуется содержимое (что она содержит). И в конкретной кассете есть еще то, что кассета где-то содержится. Надо посмотреть и то и другое. 

Посмотрел. Не визулизируется - потому что так заказано, визуализируются только коллекции. "Где-то содержится" - это правда, для кассеты всегда делается связь с cassetterootcollection. 

### 20181212 05:42
Лечу в Москву. В очередной раз. Без удовольствия... 

Захватил с собой компьютер, хотя похоже уже не надо брать - нет времени подумать, поработать. Решил немного порассуждать пока жду посдки. 

Я все больше утверждаюсь в мысли, что надо бы смигрировать в сторону автономного решения. То есть, надо сделать простую эффективную поддержку работы с одной (!) кассетой. При этом, надо сохранить возможность формирования сложных, в том числе сетевых, конфигураций. Что для этого нужно? Наверное, движок может быть смый простой. Поскольку идет работа с одной кассетой, возможно с одним fog-документом, простота и эффективность являются ключом. Я вроде и двигаюсь в этом направлении. Начал я с того, что выправляю фог-документы. В любом случае, надо предполагать ниличие разных форматов этих документов. Уже предполагается, что есть измкняемые документы, есть неизменные. Неизменные могут формировать свою базу данных. Причем эта база данных может быть технической в том смысле, что не требуется заботиться о разделении фог-документов. 

Рассмотрим модель базы данных. Есть множество fog-документов, в совокупности составляющих информационное поле системы. В любой момент можно "выключить питание", а эта база сохранится. И по ней можно все восстановить и снова вернуть стабильное рабочее состояние. Это важно. Оперативная база данных состоит из двух частей. Первая, потенциально большая, это неизменная часть, построенная на основе неизменяемых фог-документов. Может и изменяемые можно использовать, но пока я об этом думать не буду. Итак, оперативная база (данных) состоит из чего-то, что может в свою очередь сохраняться и что мы назовем статической частью и чего-то, скорее всего динамического, что позволит работать с изменяемыми фогами. Я начал построение именно с этой динамической части. И сделал это в виде общего XML-объекта, который имеет корень db и в который погружаются отдельные фоги. Вполне логично. Пока не буду заморачиваться относительно ускорения с помощью (динамических) индексных структур. Просто есть фоги и все! Каждое (?) изменение какого-то фога немедленно приводит к записи в фог-документ. Можно "поколдовать" с этим моментом, но сейчас это не актуально. 

Модель базы данных следующая. База данных представляет собой распределенное множество ЗАПИСЕЙ. В терминах RDF-графа, запись это множество высказываний относительно единого субъекта.  Здесь есть тонкость, заключающаяся в способе изменения базы данных. Я постулирую, что квантом изменения является замена записи на другое значение. Замена записи, это добавление, изменение и уничтожение. И все - разовым образом. Как это сочетается с распределенным RDF-графом? В нем часть записи может быть в одном разделе, часть в другом и т.д. По базовому замыслу, такое не допускается. Надо понять семантику построения. Кажется важно, чтобы сохранялась триплетная модель базы данных. А как это сделать???

На время, забудем про триплеты. Есть только записи. Можно (и нужно!) допустить сосуществование разных записей относительно одного субъекта. И в записи должна существовать отметка времени и функция определение того, что запись пустая. Это нужно для расределенного редактирования.  

Я уже в Москве, жду вызова на заседание суда, пытаюсь что-то сформулировать. Выясняется, что в корне рассуждений лежит простая модель распределенной системы айтемов. Пусть есть меняющееся множество айтемов, помеченных ключами. Произвольному ключу из множества ключей, соответствует один айтем из множества или не одного айтема. Есть операции put(key, item), помещающая айтем во множество. И есть операция get(key), извлекающая айтем соответствующий образцу ключа и возвращающая или айтем или некий null если нет айтемов с указанным ключом.

Если на множестве айтемов есть функция вычисления ключа key(item), то первая операция может быть сокращена до putitem(item) = put(key(item), item).

Изменение множества обязательно должны поддерживать единственность айтема по конкретному ключу. Пока put размещает айтемы с разными ключами, проблем не возникает. Если ключ повторяется, то семантика действия должна быть замена старого айтема на новый. В условиях распределенности данных, необходимо предполагать, что не всегда рационально находить именно тот айтем, который надо заменять. Или другой вариант - не всегда рационально изменять уже имеющийся айтем. Надо заменить замену на добавление. Тогда, на мгновение, появятся айтемы с одним ключем. Предыдущая семантика замены говорит, что более поздний айтем заменяет более ранний. Если допустить наличие в айтеме отметки времени, скажем проявляющейся через функцию t(item), то при наличии нескольких айтемов с одним ключом, "правильным" является тот, отметка времени которого наибольшая. Вот!

При таком подходе в принципе неплохо решается задача корректности данных в распределенной системе. Если исходить из того, что каждое следующее изменение айтема, соответствующего конкретному ключу его УТОЧНЯЕТ, то получение в качестве результата запроса более раннего значения не является сильным нарушением. Также можно провести рассуждение об относительности или неточности времени. Что было раньше - запрос на получение или запрос на изменение? И так ли важно точное "раньше"? Кроме того, частичная потеря данных в ряде случаев может компенсироваться "старыми" данными. Это можно и концептуализировать. Например, могут быть специально организованы кеши данных, когда сохраняются варианты айтемов с максимально поздней временной отметкой. И тогда, использование кешированных данных может быть очень рациональным. Например, когда информационная система вынуждена в какой-то ситуации работать off-line.

Еще одна семантическая особенность модели - уничтожение айтема. Для полноты операций редактирования, нужно уничтожение айтема по заданному ключу del(key). Что это должно означать? Уничтожение ключа "навсегда"? - сомнительно. Уничтожение всех айтемов с данным ключем? - также сомнительно. Наиболее симпатично выглядит модель, когда уничтожение точно соответствует замене. Только замена идет на айтем, который в дальнейшем рассматривается как "нулевой". Такая схема не противореичт возможности снова активировать айтем с заданным ключом. null - всего-лишь значение. Но стандартный null нам неподходит, нам нужны и ключ у этого значения и отметка времени. Технически, это деалется через функцию, которая вырабатывает указание того, что данный айтем нулевой. Соответственно, нас интересует генерация нулевого значения с заданным ключем. Наверное, можно испльзовать любой генератор. Но мне симпатичнее идея, что задано преобразование (функция item->item), переводящая "нормальный" айтем в "нулевой". Отметка времени появится при операции put().

### 20181213 07:03
Идея с функцией кажется симпатичной из-за того, что преобразование (функция) может быть организована как биекция и иметь обратную функцию, применяемую в особых ситуациях, возможно для реализации отката при транзакции.

Следующий момент - XML-реализация модели. Айтемы могут быть реализованы XML-элементами, построенными по правилам RDF-XML. Существенным моментом в применении этих правил является то, что все (!) высказывания относительно одного субъека группируются в единый элемент, а элементы с одним идентификатором rdf:about являются разными версиями, отличающиеся разными временными отметками, более поздняя - побеждает. Технически, временную отметку можно сделать как атрибут напр mt в стандартном формате, напр. mt="". Аналогично, решается вопрос с отмечанием "нулевого" или "пустого" значения, напр. через атрибут del="true". 
Здесь вроде нет значение, либо атрибут есть, либо его нет. Альтернативой могло бы показаться использование типа айтема и формирование его в специальном виде типа 
```
<delete rdf:about="..."/>
```
Но при таком подходе, мы "портим" имевшийся тип элемента, чего делать не хотелось бы. Да и разница не такая большая - указанная конструкция уничтожения, про правилам RDF, соотвествует триплету 
```
<...> a <delete> .
```
А предложенное решение триплету
```
<...> <del> "true" .
```
Получается, что для того, чтобы избавиться от ненужного "true", можно породить что-то вроде триплета
```
<...> <meta> <delete> .
```
где отношение meta может быть разным, в том числе - уничтожением. Вот так... Сразу и не осмыслишь такие глубокие идеи!!! Я то ли шучу, то ли не шучу... Еще довод в пользу последнего решения: объектные отношения потенциально эффективнее атрибутных.

А что насчет переименования или отождествления? Я вводил оператор
```
<substitute old-id=".." new-id="..."/>
```
Тогда как введенным в OWL стандартным отношением 
```
<subj> owl:SameAs <obj> .
```
В принципе, такое решение выглядит более идейным. Однако, какая семантика может быть за таким отождествлением? Особенно, в контексте распределенности и множественности записей. Само название отношения формирует представление о нем как о симметричном (коммутативном).



Один из важнейших вопросов - совместимость с RDF. Здесь базово действует стандартная схема, перевода XML в RDF и обратно. Это означает, что имеющиеся в XML (fog) элементы (записи) факторизуются по идентификатору rdf:about по признаку отметки времени. После этого, записи превращаются в множество триплетов по известной процедуре. Обратная процедура происходит через объединение триплетов в записи по общему субъекту. Некоторый вопрос имеется в том, какие отметки времени должны быть проставлены или не должны быть проставлены при сформированных записях в случае их отсутствия. 

Важно, что RDF не поддерживает множественность записей с одним идентификатором. Это, в частности означает, что массив RDF нельзя редактировать на изменение записей или уничтожение записей. Можно добавлять записи. Надо ли пользоваться этим последним свойством - еще вопрос.  

Очень существенным является вопрос о разделении базы данных на секции (разделы др.). XML-секция или fog-секция, это множество записей, выстроенных по укзанных ранее правилам. Здесь не видно ограничений. Разбиение может быть каким угодно и можно переставлять записи из одних секций в другие. Можно создавать какие-то дополнительные правила типа того, что в одной секции, можно устранять одноименные записи с более ранней временной отметкой если есть запись с боле поздней. Такой процесс можно назвать "усушкой". Сейчас это не существенно, семантика понятна и прозрачна. И набор секций, который войдет в текущую базу данных, также может быть достаточно произвольным. 

Но секции могут иметь логическое построение RDF, т.е. "плоское" множество триплетов. Плоское, это потому, что нет дополнительных структурирующих к триплетам конструкций. Семанитика RDF-секции заключается в том, что это прямая "развертка" максимально "усушенной" XML-секции. Есть прямой процесс преобразования XML -> RDF и есть обратное преобразование RDF -> XML. Кстати, в случае отсутствия отметки времени в записи, она самая "слабая" и любая другая запись с отметкой ее "побеждает". 

Мы будем предполагать, что RDF-секции не изменяемые. Схема формирования секции видится довольно простой: берется сколько-то XML-секций, объединяем, усушиваем и преобразуем. После этого, можно RDF-секцию можно использовать совместно с XML и другими RDF-секциями в единой базе данных. При этом, RDF-секцию можно превратить в XML-секцию, но это будут уже не те секции из которых она была собрана. 

Логика функционирования базы данных видится следующей. Имеется распределенное множество XML и RDF-секций. Из них формируется распределенная база данных. При этом, XML-секции могут изменяться, а RDF - нет. Для этой системы есть указанный базис put(), get(). get() делает выборку, находя в секциях нужную запись, оператор put() вставляет айтем в одну из XML-секций и текущей отметкой времени. 

Кстати, не отметил. Построение с использованием записей, хорошо не для всех структуризаций. Важно, чтобы прямых ссылок было не много и чтобы записи не разрастались. 

### 20181215 08:17
И вот, я снова дома. Вчера постарался отдохнуть, сегодня надо начать работать. Кстати, погода хорошая, снег кончил падать, ветра нет, -8. Надо будет погулять. С прогулками одна проблема - "отравление кислородом" и потом спать хочется. 

Для XML-секций пока не было ни каких ограничений. И произвольное разбиение записей и дублирование. И вот, пора ввести атрибуты. Пока только один. Похоже, это должен быть атрибут типа bucket "ведро", возможно также heap - куча, selection - набор. Этот атрибут в модели представляет собой место, куда направлена операция put(). Можно и get(), но это будет уже другой смысл. Пусть put(). А get() работает как раньше. А можно еще использовать уже введенное понятие секции (section). Соответственно, появляется необходимость идентифицировать секцию. Итак, put(item, section) - это команда помещения айтема в указанную секцию. Но get(key) - выборка из всех активированных секций. Может нужна и команда get(key, section), но пока я не буду об этом думать. 

Для чего это нужно? В первую очередь - для обеспечения локальности какой-то группы изменений. Это потому, что секцию мы можем подключать к базе данных, а можем не подключать. Соотвественно, за манипулящиями секциями могут стоять полномочия пользователя на запись и изменение информации. Сейчас используется понятие владельца секции. Соответственно, вводится понятие пользователя. Идентификатор пользователя сопровождает запрос на изменение. Если находится секция, имеющая такого владельца, то именно туда может осуществляться запись измененения. Текущее предположение, что секций, у одного владельца может быть несколько (много) и что есть два дополнительных признака: признак writable, это у секции и направление, куда надо писать, это у пользователя. Многовато... 

### 20181216 07:36
А еще в модели я забыл про контент, т.е. файлы. Может так и надо, но все же как-то это все должно быть увязано. 

У меня есть "долги" - два дела. Надо разобраться с редакцией научного журнала, который на меня "натравил" Асеев и надо сделать еще одно экспертное заключение. Попробую день начать с этих дел. 

12:28

Долги сделал. 

Пока у меня болела голова, я подумал над конструкцией записи базы данных. Все не слишком сложно, что-нибудь типа:
```
Record = 
  id: String,
  mT: Longinteger,
  em: Boolean,
  props: [Prop];
Prop =  
  pred: String,
  obj: Obj;
Obj =
  empty^none,
  iri^  String,
  str^  String,
  int^  Integer,
  ...
  
```

Вариантом на эту тему может быть разделение объекных свойств (ссылок) и Datatype свойств (атрибутов).
Последовательность таких записей и является последовательностью, с каноническими свойствами, позволяющими реализовывать полный набор операций редактирования.  

Потом вспомнилось, что я не доделал к универсальной последовательности универсальный индекс. А то, что есть, построено на других принципах. Если разобраться, то вроде ничего сложного нет. Надо прикинуть. 






